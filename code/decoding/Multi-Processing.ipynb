{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages \n",
    "import os,sys\n",
    "import numpy as np\n",
    "import nilearn\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nilearn.input_data import NiftiMasker \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def set_dict():\n",
    "    ana_dict = {\n",
    "        \"Dataset\": None,\n",
    "        \"Fit_Time\": None,\n",
    "        \"CV_Time\": None,\n",
    "        \"CV_Score\": None,\n",
    "        \"SVC\": None\n",
    "    }\n",
    "    \n",
    "    return ana_dict;\n",
    "\n",
    "# Get the data - mask nifti, behavioral file, dataset nifti\n",
    "def prepare_data(dataset, mask, stim):\n",
    "    print(\"Preparing data.......\")\n",
    "    _dict = set_dict()\n",
    "    #image mask\n",
    "\n",
    "    _dict[\"Dataset\"] = dataset.split(\"/\")[-1]\n",
    "    #load behavioral data into a pandas df\n",
    "    behavioral = pd.read_csv(stim, sep=\"\\t\")\n",
    "\n",
    "    # look at original unique labels \n",
    "    print(\">ORIGINAL behavioral list: \", behavioral[\"Label\"].unique())\n",
    "\n",
    "    #grab conditional labels and set up milkshake\n",
    "    behavioral[\"Label\"] = behavioral.replace(['HF_LS_receipt', 'LF_LS_receipt', 'LF_HS_receipt', 'HF_HS_receipt'], 'milkshake')\n",
    "\n",
    "    y = behavioral[\"Label\"]\n",
    "    print(\">MODIFIED behavioral list \", y.unique()) # make sure all the milkshake receipts have been replaced with \"milkshake\"\n",
    "\n",
    "    #restrict data to our target analysis \n",
    "    condition_mask = behavioral[\"Label\"].isin(['milkshake', \"h20_receipt\"])\n",
    "    y = y[condition_mask]\n",
    "\n",
    "    #confirm we have the # of condtions needed\n",
    "    print(\">FINAL behavioral list \", y.unique())\n",
    "    masker_start = time.time()\n",
    "    masker = NiftiMasker(mask_img=mask, standardize=True, memory=\"nilearn_cache\", memory_level=5)\n",
    "    X = masker.fit_transform(dataset)\n",
    "    # Apply our condition_mask\n",
    "    X = X[condition_mask]\n",
    "    masker_time = time.time() - masker_start\n",
    "    # set time in dict\n",
    "    mask_size = sys.getsizeof(masker)\n",
    "    print(\"MASK SIZE: \", mask_size)\n",
    "    return [X, y, _dict, masker];\n",
    "\n",
    "def set_pipeline(data):\n",
    "    print(\"Generating pipeline....\")\n",
    "    # PREDICTION FUNCTION\n",
    "    from sklearn.svm import SVC\n",
    "    svc = SVC(kernel='linear', max_iter=1000)\n",
    "    print(svc)\n",
    "    # FEATURE SELECTION\n",
    "    feature_selection = SelectKBest(f_classif, k=500)\n",
    "    anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "    fit_start = time.time()\n",
    "    print(\"fitting model......\")\n",
    "    X = data[0]\n",
    "    y = data[1]\n",
    "    X_size = sys.getsizeof(X)\n",
    "    print(\"X SIZE: \", X_size)\n",
    "    _dict = data[2]\n",
    "    anova_svc.fit(X,y)\n",
    "    y_pred = anova_svc.predict(X)\n",
    "    print(\">>Initial Prediction: \", y_pred)\n",
    "    fit_time = time.time() - fit_start\n",
    "    _dict[\"Fit_Time\"] = fit_time\n",
    "    \n",
    "    return [anova_svc, _dict, svc, feature_selection];\n",
    "\n",
    "def make_img(dataset, svc, masker, feature_selection):\n",
    "    print(\"Making Image........\")\n",
    "    # Here is the image \n",
    "    coef = svc.coef_\n",
    "    # reverse feature selection\n",
    "    coef = feature_selection.inverse_transform(coef)\n",
    "    # reverse masking\n",
    "    weight_img = masker.inverse_transform(coef)\n",
    "    # Use the mean image as a background to avoid relying on anatomical data\n",
    "    from nilearn import image\n",
    "    mean_img = image.mean_img(dataset)\n",
    "    mean_img.to_filename('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives/code/decoding/milkshake_vs_h2O/images/inclusive/all_mean_nimask.nii')\n",
    "\n",
    "    # Create the figure\n",
    "    from nilearn.plotting import plot_stat_map, show\n",
    "    display = plot_stat_map(weight_img, mean_img, title='Milkshake vs. H2O')\n",
    "    display.savefig('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives/code/decoding/milkshake_vs_h2O/images/inclusive/all_SVM_nimask.png')\n",
    "    # Saving the results as a Nifti file may also be important\n",
    "    weight_img.to_filename('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives/code/decoding/milkshake_vs_h2O/images/inclusive/all_SVM_nimask.nii')\n",
    "\n",
    "    \n",
    "def run_nested_cv(data_list, pipe_list, k_range):\n",
    "    print(\"K_range: \", k_range)\n",
    "    # NESTED CROSS VALIDATION\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    # set params\n",
    "    X = data_list[0]\n",
    "    y = data_list[1]\n",
    "    CV_start = time.time()\n",
    "    print(\"running nested CV......\")\n",
    "    pipeline = pipe_list[0]\n",
    "    _dict = pipe_list[1]\n",
    "    grid = GridSearchCV(pipeline, param_grid={'anova__k': k_range}, verbose=1, cv=5, n_jobs=3)\n",
    "\n",
    "    cv_score = cross_val_score(grid, X, y, cv=5, n_jobs=3)\n",
    "    mean_score = np.mean(cv_score)\n",
    "    print(\"Nested CV score: %.4f\" % mean_score)\n",
    "    CV_time= time.time() - CV_start\n",
    "    _dict[\"CV_Score\"] = mean_score\n",
    "    _dict[\"CV_Time\"] = CV_time\n",
    "    \n",
    "    return _dict;\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "def main():\n",
    "    mask='/projects/niblab/bids_projects/Experiments/ChocoData/images/bin_mask.nii.gz'\n",
    "    #mask='/Users/nikkibytes/Documents/lab/test_imgs/bin_mask.nii.gz'\n",
    "    #our behavioral csv file \n",
    "    stim = '/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/milkshake_all.csv'\n",
    "    #stim='/Users/nikkibytes/Documents/lab/test_imgs/sub-001.csv'\n",
    "    #our dataset concatenated image \n",
    "    dataset='/projects/niblab/bids_projects/Experiments/ChocoData/images/milkshake_all.nii.gz'\n",
    "    #dataset='/Users/nikkibytes/Documents/lab/test_imgs/sub-001.nii.gz'\n",
    "    data_list = prepare_data(dataset, mask, stim)\n",
    "    masker = data_list[3]\n",
    "    #print(\"DATA PREP FINISHED..... data_list: \", data_list) \n",
    "    pipe_list = set_pipeline(data_list)\n",
    "    svc = pipe_list[2]\n",
    "    feature_selection = pipe_list[3]\n",
    "    #print(\"DICTIONARY: \", pipe_list[1])\n",
    "    #p = Pool(processes = 4) \n",
    "    k_range = [ 15 ]#, 30, 50, 100, 150, 300, 500, 1000, 3000, 1500, 5000]\n",
    "    #from functools import partial\n",
    "    #func = partial(run_nested_cv, data_list, pipe_list)\n",
    "    results = run_nested_cv(data_list,pipe_list,k_range)\n",
    "    start = time.time()\n",
    "    #cv_score =  p.map(func, k_range)\n",
    "    results[\"SVC\"] = svc\n",
    "    make_img(dataset, svc, masker, feature_selection)\n",
    "    #p.close()\n",
    "    #p.join()\n",
    "    #print(cv_score)\n",
    "    print(\"Time: \", (time.time() - start)) \n",
    "    #results = pipe_list[1] \n",
    "    #results[\"CV_Score\"] = cv_score\n",
    "    print(\">>>RESULTS: \", results)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
