{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chocolate Milkshake Betaseries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Paradigm**\n",
    "\n",
    "Functional Tasks: \n",
    "\n",
    "    milkshake pic, milkshake receipt, h20 pic, h20 receipt, milkshake minus h20, milkshake plus h20, rinse\n",
    "\n",
    "Furthermore, `milkshake` is broken down into the following specifities:   \n",
    "      \n",
    "    HF(high fat, HS(high sugar), and respectively, LF(low fat), LS(low sugar)   \n",
    "\n",
    "with the following relationships:  \n",
    "    \n",
    "    HF_HS, HF_LS, LF_HS, LF_LS\n",
    "\n",
    "\n",
    "Example set of onsets for a subject:  \n",
    "\n",
    "\n",
    "`\n",
    "$ /pwd ~/preprocessed/sub-001/ses-1/func/onsets\n",
    "mkB_h20_pic.ev          mkB_HS_plus_h20.ev      mkB_rinse.ev            mkC_HF_LS_receipt.ev    mkC_milkshake_pic.ev\n",
    "mkB_h20_receipt.ev      mkB_LF_HS_minus_h20.ev  mkC_h20_pic.ev          mkC_HS_plus_h20.ev      mkC_rinse.ev\n",
    "mkB_HF_HS_minus_h20.ev  mkB_LF_HS_receipt.ev    mkC_h20_receipt.ev      mkC_LF_HS_minus_h20.ev\n",
    "mkB_HF_HS_receipt.ev    mkB_LF_LS_receipt.ev    mkC_HF_HS_minus_h20.ev  mkC_LF_HS_receipt.ev\n",
    "mkB_HF_LS_receipt.ev    mkB_milkshake_pic.ev    mkC_HF_HS_receipt.ev    mkC_LF_LS_receipt.ev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "\n",
    "from IPython.core import display as ICD\n",
    "from os import listdir\n",
    "from shutil import rmtree\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup feat files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Chocolate Milkshake** paradigm has multiple tasks:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file(sub_id, ses_id, trial_id, output_dir, task,data_dict):\n",
    "    with open(os.path.join('/projects/niblab/experiments/chocolate_milkshake/data/code/beta_design.fsf'),'r') as infile:\n",
    "        tempfsf=infile.read()\n",
    "        #\n",
    "        if not os.path.exists(os.path.join(output_dir, \"design_files\")):\n",
    "            os.makedirs(os.path.join(output_dir, \"design_files\"))\n",
    "        #print(output_dir)\n",
    "        design_fileout = os.path.join(output_dir, \"design_files/%s_%s_%s_feat1.fsf\"%(sub_id, ses_id, trial_id))\n",
    "        out_param = data_dict[sub_id][task][\"TRIALS\"][\"TRIAL%s\"%trial_id][\"OUTPUT\"]\n",
    "        func_param = data_dict[sub_id][task][\"FUNCRUN\"]\n",
    "        confound_param = data_dict[sub_id][task][\"CONFOUND\"]\n",
    "        trial_param = data_dict[sub_id][task][\"TRIALS\"][\"TRIAL%s\"%trial_id][\"TRIAL\"]\n",
    "        nuis_param = data_dict[sub_id][task][\"TRIALS\"][\"TRIAL%s\"%trial_id][\"NUIS\"]\n",
    "\n",
    "        tempfsf = tempfsf.replace(\"OUTPUT\", out_param)\n",
    "        tempfsf = tempfsf.replace(\"FUNCRUN\", func_param) \n",
    "        tempfsf = tempfsf.replace(\"CONFOUND\", confound_param)\n",
    "        tempfsf = tempfsf.replace(\"TRIAL\", trial_param)\n",
    "        tempfsf = tempfsf.replace(\"NUIS\", nuis_param)\n",
    "\n",
    "        for i in range(6):\n",
    "            moco = data_dict[sub_id][task][\"MOCO%i\"%i]\n",
    "            tempfsf = tempfsf.replace(\"MOCO%i\"%i, moco)\n",
    "        try:\n",
    "            with open(design_fileout,'w') as outfile:\n",
    "                outfile.write(tempfsf)\n",
    "            outfile.close()\n",
    "        except:\n",
    "            print(\"BAD SUBJECT \", sub_id)\n",
    "        infile.close()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fsf(input_dir, deriv_dir, ses_id):\n",
    "    \n",
    "    ses_id=ses_id\n",
    "    data_dict= {}\n",
    "    # start loop -- looping through subjects\n",
    "    subject_list = glob.glob(os.path.join('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives', 'sub-*/%s'%ses_id))\n",
    "    for sub_path in subject_list:\n",
    "        sub_id=sub_path.split(\"/\")[-2]\n",
    "        \n",
    "        functional_tasks = glob.glob(os.path.join(sub_path, 'func/*milkshake*preproc_brain.nii.gz'))\n",
    "        if sub_id not in data_dict:\n",
    "            data_dict[sub_id] = {}\n",
    "                \n",
    "        \n",
    "        for functional in functional_tasks: # SECOND LOOP -- looping through RUNS\n",
    "            task=functional.split(\"/\")[-1].split(\"_\")[2].split(\"-\")[1]\n",
    "            analysis_folder=os.path.join('/projects/niblab/experiments/chocolate_milkshake/bids/derivatives/preprocessed/%s/%s'%(sub_id,ses_id), \"analysis\")\n",
    "            #print(analysis_folder)\n",
    "            output_dir = os.path.join(analysis_folder, 'beta/task-%s'%task)\n",
    "            \n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            \n",
    "            confound_file = os.path.join(sub_path, \"func/motion_assessment/%s_%s_task-%s_bold_space-MNI152NLin2009cAsym_preproc_brain_confound.txt\"%(sub_id,ses_id, task))\n",
    "                \n",
    "            data_dict[sub_id][task] = {\n",
    "                \"TRIALS\" : { },\n",
    "                \"CONFOUND\" : confound_file,\n",
    "                \"FUNCRUN\" : functional\n",
    "              }           \n",
    "            \n",
    "            for i in range(6):\n",
    "                motcor=os.path.join(sub_path, 'func','motion_assessment', 'motion_parameters','%s_%s_task-%s_moco%s.txt'%(sub_id,ses_id, task,i))\n",
    "                data_dict[sub_id][task]['MOCO%i'%i] = motcor\n",
    "            \n",
    "            \n",
    "            subj_trials = sorted(glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/evs/%s*trial*.txt'%task.replace('milkshake', 'mk')))\n",
    "            \n",
    "            if not subj_trials:\n",
    "                pass\n",
    "            else:\n",
    "                for trial_file in subj_trials:\n",
    "                    _id = sub_id.split(\"-\")[1]\n",
    "                    _id = _id[1:]\n",
    "                    trial_id = trial_file.split(\"/\")[-1].split(\".\")[0]\n",
    "                    #print(trial_id)\n",
    "                    nuis_file = os.path.join('/projects/niblab/experiments/chocolate_milkshake/data/evs', '%s.txt'%trial_id.replace('trial', 'nuis'))\n",
    "                    #print(nuis_file)\n",
    "                    fileout = os.path.join(output_dir, \"%s_%s_%s\"%(sub_id, ses_id,trial_id))\n",
    "                    #print(fileout)\n",
    "                    data_dict[sub_id][task][\"TRIALS\"][\"TRIAL%s\"%trial_id] = {\"TRIAL\" : trial_file, \"NUIS\": nuis_file, \"OUTPUT\" : fileout}\n",
    "                    make_file(sub_id, ses_id, trial_id,output_dir, task, data_dict)\n",
    "                    \n",
    "                    \n",
    "    return(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_paths():\n",
    "    #global input_dir\n",
    "    #global deriv_dir\n",
    "    print(\"[INFO] setting directory paths\")\n",
    "    input_dir =  '/projects/niblab/experiments/chocolate_milkshake'\n",
    "        \n",
    "    deriv_dir= os.path.join(input_dir, 'bids/derivatives')\n",
    "\n",
    "    return input_dir, deriv_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] setting directory paths\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    ses_id='ses-1'\n",
    "    input_dir, deriv_dir=set_paths()\n",
    "    data_dict=create_fsf(input_dir, deriv_dir,ses_id)\n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run slurm jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_slurm(subject_list):\n",
    "    for subj in subject_list[:1]:\n",
    "        #print(subj)\n",
    "        slurm_cmd= \"sbatch --array={}%1 /projects/niblab/experiments/chocolate_milkshake/data/code/beta_run.job {}\".format(subj,'receipt')\n",
    "        print(slurm_cmd)\n",
    "        #os.system(slurm_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_file_slurm(subject):\n",
    "    fsfs=glob.glob(os.path.join('/projects/niblab/experiments/chocolate_milkshake/data/bids/derivatives/preprocessed/{}/ses-1/analysis/beta/task*C/design_files/*receipt_*.fsf'.format(subject)))\n",
    "    for fsf in fsfs:\n",
    "        slurm_cmd = \"sbatch /projects/niblab/experiments/chocolate_milkshake/data/code/beta_by_file.job {}\".format(fsf)\n",
    "        #print('[INFO] submitted: \\n', slurm_cmd)\n",
    "        #os.system(slurm_cmd)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '4', '5', '9', '11']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_list =  [x.split(\"/\")[-2].split(\"-\")[1].strip('0') for x in glob.glob(os.path.join('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives', 'sub-*/ses-1'))]\n",
    "subject_list[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit slurm files in a loop: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch --array=1%1 /projects/niblab/experiments/chocolate_milkshake/data/code/beta_run.job receipt\n"
     ]
    }
   ],
   "source": [
    "run_slurm(subject_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit slurm jobs by running fsf files individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] submitted slurm jobs.\n"
     ]
    }
   ],
   "source": [
    "sub_ids=[x.split('/')[-2] for x in glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/bids/derivatives/preprocessed/sub-015/ses-1')]\n",
    "for subject in sub_ids:\n",
    "    #print(subject)\n",
    "    by_file_slurm(subject)\n",
    "\n",
    "print('[INFO] submitted slurm jobs.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View your job queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!squeue -u nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_check():\n",
    "    data_dict={}\n",
    "    ses1_subjects=glob.glob(os.path.join(\"/projects/niblab/experiments/chocolate_milkshake/bids/derivatives/preprocessed/sub-*/ses-1\"))\n",
    "    for subj_folder in ses1_subjects:\n",
    "        subject=subj_folder.split(\"/\")[-2]\n",
    "        if subject not in data_dict:\n",
    "            data_dict[subject] = []\n",
    "            \n",
    "        feats=glob.glob(os.path.join(subj_folder, 'analysis/beta/task*/*.feat/'))\n",
    "        if not feats:\n",
    "            #print(\"[INFO] nothing found for %s\"%subject)\n",
    "            data_dict[subject] = \"MISSING\"\n",
    "        else:\n",
    "            for feat in feats:\n",
    "                #print(feat)\n",
    "                stats_folder=os.path.join(feat, \"stats\")\n",
    "                #print(stats_folder)\n",
    "                if not os.path.exists(stats_folder):\n",
    "                    print(listdir(feat))\n",
    "                    print(feat)#.split(\"/\")[-1])\n",
    "                    #data_dict[subject].append(feat)\n",
    "                    # remove folder if its bad/ no stats folder\n",
    "                    #rmtree(feat)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "                    #print(\"[INFO] passed\")\n",
    "                    #data_dict[subject]['good'].append(feat.split('/')[-2])\n",
    "    #print(data_dict)\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quality_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_folders=sorted(glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/bids/derivatives/preprocessed/sub-*'))\n",
    "\n",
    "data_dict={}\n",
    "bad_subs=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the subjects and the feat1 pe files, fill in data dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in subject_folders:\n",
    "    subject_id=folder.split(\"/\")[-1]\n",
    "    #print(os.path.join(folder,'ses-1/analysis/beta/*.feat'))\n",
    "    tasks=glob.glob(os.path.join(folder,'ses-1/analysis/beta/*'))\n",
    "    #print(tasks)\n",
    "    if not tasks:\n",
    "        bad_subs.append(subject_id)\n",
    "    else:\n",
    "        if subject_id not in data_dict:\n",
    "            data_dict[subject_id]={}\n",
    "        for task_folder in tasks:\n",
    "            #print(task_folder)\n",
    "            task=task_folder.split(\"/\")[-1].split('.')[0]\n",
    "            #print(task)\n",
    "            if task not in data_dict[subject_id]:\n",
    "                data_dict[subject_id][task]={}\n",
    "            pes=glob.glob(os.path.join(task_folder, '*.feat'))\n",
    "            data_dict[subject_id][task]=pes\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate  \n",
    "`fslmerge : concatente image files into a single output.`   \n",
    "  \n",
    "In this step we use the `fslmerge` command to combine the `pe.nii.gz` files by subject of the same condition.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_path='/projects/niblab/experiments/chocolate_milkshake/data/betaseries'\n",
    "concat_path=\"/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] running fslmerge command...\n",
      "fslmerge -t [OUTPUT FILENAME][PE FILES]\n",
      "[INFO] image concatenation process complete.\n",
      "[INFO] find images here:  /projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] running fslmerge command...\\nfslmerge -t [OUTPUT FILENAME][PE FILES]\")\n",
    "for subject_id in data_dict:\n",
    "    for task in data_dict[subject_id]:\n",
    "        pes=data_dict[subject_id][task]#[trial]\n",
    "        #print(pes)\n",
    "        #print(trial)\n",
    "        #filename=trial.replace(subject_id+\"_\", \"\")\n",
    "        outfile = os.path.join(concat_path, \"%s_%s\"%(subject_id, task))\n",
    "        #print(outfile)\n",
    "        if not pes:\n",
    "            bad_subs.append(subject_id)\n",
    "        else:\n",
    "            pe_str = \" \".join(pes)\n",
    "            fslmerge_cmd=\"/projects/niblab/modules/software/fsl/5.0.10/bin/fslmerge -t %s %s\"%(outfile, pe_str)\n",
    "            #print(\"[INFO] running fsl merge command...\")\n",
    "            #print(fslmerge_cmd, \"\\n\")\n",
    "            #os.system(fslmerge_cmd)\n",
    "\n",
    "print(\"[INFO] image concatenation process complete.\")\n",
    "print('[INFO] find images here: ',concat_path )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the created files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat/sub-001_task-milkshakeB.nii.gz',\n",
       " '/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat/sub-001_task-milkshakeC.nii.gz',\n",
       " '/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat/sub-004_task-milkshakeA.nii.gz',\n",
       " '/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat/sub-004_task-milkshakeB.nii.gz']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fslmerged_files=glob.glob(os.path.join(concat_path,'*.nii.gz'))\n",
    "fslmerged_files[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill data dictionary with concatenated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nifti in fslmerged_files:\n",
    "    task=nifti.split(\"/\")[-1].split(\"_\")[1].split('.')[0]\n",
    "    subject_id=nifti.split(\"/\")[-1].split(\"_\")[0]\n",
    "    key=nifti.split(\"/\")[-1].split(\".\")[0].split('_')[1]\n",
    "    key=key+\"_concat\"\n",
    "    #print(subject_id)\n",
    "    #data_dict[subject_id][task]['concat']=nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] transform functionals to match the mask.\n",
      "[INFO] transformation process complete.\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] transform functionals to match the mask.')\n",
    "\n",
    "reference_nifti='/projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.nii.gz'\n",
    "reference_mat='/projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.mat'\n",
    "for nii in fslmerged_files:\n",
    "    \n",
    "    # setup and run flirt\n",
    "    nii=nii.replace('.nii.gz', '')\n",
    "    out=nii+'_3mm'\n",
    "    flirt_cmd=\"flirt -in {} -ref {} -init {} -applyxfm -out {}\".format(nii, reference_nifti, reference_mat, out)\n",
    "    #print('[INFO] flirt command: \\n{}'.format(flirt_cmd))\n",
    "    #os.system(flirt_cmd)\n",
    "    \n",
    "    fslmaths_cmd='fslmaths {} -thr 0.9 {}'.format(out,out)\n",
    "    #print('[INFO] fslmaths command: \\n{}'.format(fslmaths_cmd))\n",
    "    #os.system(fslmaths_cmd)\n",
    "    \n",
    "print('[INFO] transformation process complete.')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp ROIS  \n",
    "This step we warp MNILin152 template into MNIAsym152 BOLD space.  \n",
    "\n",
    "To warp the ROIs into the right space   \n",
    "-- Warp ROIs into MNI_Asymmetrical Space   \n",
    "--- *This can be done at any point, I did it here.\n",
    "\n",
    "* Warp MNILin152 template into MNIAsym152 BOLD space  \n",
    "\n",
    "* Use the naming.xlsx template to make flirt commands\n",
    "* Apply the flirt warp to all the ROIs from the chocolate decoding analysis (warp_rois.job)    \n",
    "  \n",
    "ROIs location on renci: `/projects/niblab/parcellations/chocolate_decoding_rois`   \n",
    "\n",
    "Big Brain 300: `/projects/niblab/parcellations/chocolate_decoding_rois/old_rois/bigBrain300_atlas`\n",
    "  \n",
    "`flirt`: the main program that performs affine registration. The options we use here:  \n",
    "* `-in`, an input  \n",
    "* `-ref`, a reference volume  \n",
    "* `applyxfm`, `-init` and `-out`, apply a saved transformation to a volume   \n",
    "\n",
    "  \n",
    "  \n",
    "*For these usages the reference volume must still be specified as this sets the voxel and image dimensions of the resulting volume.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example command   \n",
    "    \n",
    "  `/projects/niblab/modules/software/fsl/5.0.10/bin/flirt -in /projects/niblab/parcellations/chocolate_decoding_rois/seperate_ROIs_gust_atlas/AI_35_23_-6.nii.gz -applyxfm -init /projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.mat -out /projects/niblab/parcellations/chocolate_decoding_rois/seperate_ROIs_gust_atlas_ace/AI_35_23_-6_asymPREPspace.nii.gz -ref /projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.nii.gz`\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To warp ROIs...\n",
    "\n",
    "* First need to do the `.mat` file from the MNI2mm to the asymetrical\n",
    "\n",
    "\n",
    "`flirt -ref ../mni_icbm152_nlin_asym_09c_nifti/mni_icbm152_nlin_asym_09c/mni_icbm152_t1_tal_nlin_asym_09c_brain.nii.gz -in /projects/niblab/modules/software/fsl/5.0.10/data/standard/MNI152_T1_2mm_brain.nii.gz -out mni2mm2ace -omat mni2mm2ace`\n",
    "  \n",
    "  \n",
    "* Then apply the `.mat` file to warp the ROIS\n",
    "  \n",
    "`flirt -ref mni2mm2ace.nii.gz -in gust_atlas+.nii -applyxfm -init mni2mm2ace -out test`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to use flirt together with the `highres2example_func.mat `\n",
    "transformation file in order to transform your mask.\n",
    "For example:  \n",
    "   `flirt -in S02brain_BET_5_pve_0_thr -ref example_func -init  \n",
    "highres2example_func.mat -applyxfm -out S02brain_BET_5_pve_0_thr_func`\n",
    "\n",
    "   `fslmaths S02brain_BET_5_pve_0_thr_func -thr 0.9 -bin  \n",
    "S02brain_BET_5_pve_0_thr_func`  \n",
    "\n",
    "you need the fslmaths line to re-binarise the mask after  \n",
    "transformation, and I've used a conservative\n",
    "threshold to exclude the partial volume edges (post-interpolation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`flirt -in /projects/niblab/experiments/chocolate_milkshake/data/betaseries/fslmerge_niftis/sub-001_task-milkshakeB -ref /projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.nii.gz -init /projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.mat -applyxfm -out /projects/niblab/experiments/chocolate_milkshake/data/betaseries/fslmerge_niftis/sub-001_task-milkshakeB_func`\n",
    "\n",
    "`fslmaths /projects/niblab/experiments/chocolate_milkshake/data/betaseries/fslmerge_niftis/sub-001_task-milkshakeB_func -thr 0.9 -bin /projects/niblab/experiments/chocolate_milkshake/data/betaseries/fslmerge_niftis/sub-001_task-milkshakeB_func`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fslmeants -i /projects/niblab/experiments/chocolate_milkshake/data/betaseries/fslmerge_niftis/sub-001_task-milkshakeB.nii.gz -o /projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300/sub-001_task-milkshakeB_bb300_MNI152Asymm3mm_287_test2.txt -m /projects/niblab/parcellations/bigbrain300/MNI152Asymmetrical_3mm/bb300_MNI152Asymm3mm_287.nii.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flirt -in /projects/niblab/parcellations/bigbrain300/MNI152Asymmetrical_3mm/bb300_MNI152Asymm3mm_287 -ref /projects/niblab/parcellations/chocolate_decoding_rois/mni2mm2ace.nii.gz -init /projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.mat -applyxfm -out /projects/niblab/parcellations/bigbrain300/MNI152Asymmetrical_3mm/bb300_MNI152Asymm3mm_287_func`\n",
    "\n",
    "`fslmaths /projects/niblab/parcellations/bigbrain300/MNI152Asymmetrical_3mm/bb300_MNI152Asymm3mm_287_func -thr 0.9 -bin /projects/niblab/parcellations/bigbrain300/MNI152Asymmetrical_3mm/bb300_MNI152Asymm3mm_287_func`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ROI Timeseries  \n",
    "`fslmeants` : outputs the average timeseries of a set of voxels, or the individual timeseries for each of these voxels.  \n",
    "  \n",
    "We use rois from the BigBrain300 atlas as our reference masks, `-m`, therefore the average is taken over all voxels in the reference mask.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`example command:`  \n",
    "\n",
    "\n",
    "    fslmeants -i ~/sub-001_punish.nii.gz -o ~/3_pull_timeseries/sub-001_punish_AI_35_23_-6_asymPREPspace.nii.gz.txt -m ~/AI_35_23_-6_asymPREPspace.nii.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           3035724     batch timeseri   nbytes  R       8:14      1 largemem-0-0\n"
     ]
    }
   ],
   "source": [
    "# submit batch job\n",
    "!squeue -u nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunks(l,n):\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "\n",
    "def pull_timeseries(roi_list, bb300_path='/projects/niblab/parcellations/bigbrain300',roi_df='/projects/niblab/parcellations/bigbrain300/renaming.csv'):\n",
    "\n",
    "    \n",
    "    bad_subs=[]\n",
    "    #ICD.display(roi_df)\n",
    "\n",
    "    # load asymmetrical nifti roi files\n",
    "    asym_niftis=glob.glob(\"/projects/niblab/parcellations/bigbrain300/MNI152Asymmetrical_3mm/*.nii.gz\")\n",
    "\n",
    "    # load roi list\n",
    "    out_dir = os.path.join(beta_path, 'rois/big300')\n",
    "    #print('[INFO] OUT DIRECTORY: %s \\n'%out_dir)\n",
    "\n",
    "    #roi_df.set_index(\"final order name\", inplace=True)\n",
    "    #ICD.display(roi_df)#.head())\n",
    "\n",
    "    # run parallel job pools\n",
    "\n",
    "\n",
    "    # loop through the roi file list\n",
    "    #print(roi_list[:3])\n",
    "    for nifti in sorted(roi_list):\n",
    "        #print('[INFO] loop1')\n",
    "        subj_id = nifti.split(\"/\")[-1].split(\"_\")[0]\n",
    "        subj_condition=nifti.split(\"/\")[-1].split(\"_\")[1].split(\".\")[0]\n",
    "        #print('[INFO] roi: %s %s'%(subj_id, subj_condition))\n",
    "\n",
    "        # loop through roi reference list\n",
    "        for ref_nifti in sorted(asym_niftis):\n",
    "            #print('[INFO] reference roi: %s'%ref_nifti)\n",
    "            roi = ref_nifti.split('/')[-1].split(\".\")[0]\n",
    "            out_path = os.path.join(out_dir, \"{}_{}_{}.txt\".format(subj_id, subj_condition, roi))\n",
    "            #print(roi, out_path)\n",
    "            cmd='fslmeants -i {} -o {} -m {}'.format(nifti, out_path, ref_nifti)\n",
    "            try:\n",
    "                cmd='fslmeants -i {} -o {} -m {}'.format(nifti, out_path, ref_nifti)\n",
    "                #print(\"Running shell command: {}\".format(cmd))\n",
    "                #os.system(cmd)\n",
    "            except:\n",
    "                bad_subs.append((subj_id, subj_condition))\n",
    "        \n",
    "        #print('[INFO] finished processing for %s'%subj_id)\n",
    "\n",
    "\n",
    "    return \"%s\"%bad_subs\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading roi and reference file....\n",
      "[INFO] 224 task roi nifti files being processed.\n",
      "[INFO] chunksize: 10\n",
      "[INFO] process complete.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "# load roi\n",
    "print(\"[INFO] loading roi and reference file....\")\n",
    "\n",
    "# task rois loaded\n",
    "task_rois=glob.glob(os.path.join(concat_path,'*_3mm.nii.gz'))\n",
    "#task_rois[:5]\n",
    "print(\"[INFO] {} task roi nifti files being processed.\".format(len(task_rois)))\n",
    "\n",
    "chunksize=10\n",
    "print(\"[INFO] chunksize: {}\".format(chunksize))\n",
    "chunk_list=chunks(task_rois, chunksize)\n",
    "#roi_df['network']\n",
    "# pull timeseries by rois --fslmeants command\n",
    "\n",
    "\n",
    "with Pool(5) as p:\n",
    "    p.map(pull_timeseries, chunk_list)\n",
    "print(\"[INFO] process complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick view of roi text files made:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-049_task-milkshakeC_bb300_MNI152Asymm3mm_001.txt',\n",
       " 'sub-001_task-milkshakeB_bb300_MNI152Asymm3mm_001.txt',\n",
       " 'sub-112_task-milkshakeD_bb300_MNI152Asymm3mm_001.txt',\n",
       " 'sub-097_task-milkshakeC_bb300_MNI152Asymm3mm_001.txt',\n",
       " 'sub-020_task-milkshakeC_bb300_MNI152Asymm3mm_001.txt']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view timeseries \n",
    "listdir('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300')[:5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Timeseries into Matrix  \n",
    "Combine timeseries roi files into, **one file per condition per participant**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-150', 'sub-151', 'sub-154']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_ids=list(data_dict.keys())\n",
    "subject_ids[-3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/sub-001_task-milkshakeC_vlPFC_R.txt',\n",
       " '/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/sub-001_task-milkshakeC_vlThalamus_L.txt',\n",
       " '/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/sub-001_task-milkshakeC_vlThalamus_R.txt',\n",
       " '/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/sub-001_task-milkshakeC_vmPFC_L.txt',\n",
       " '/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/sub-001_task-milkshakeC_vmPFC_R.txt']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_txts[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] making subject condition files from rois.\n",
      "[INFO]error with sub-015 condition task-milkshakeC, passing...\n",
      "[INFO]error with sub-032 condition task-milkshakeD, passing...\n",
      "[INFO]error with sub-033 condition task-milkshakeC, passing...\n",
      "[INFO]error with sub-081 condition task-milkshakeC, passing...\n",
      "[INFO]error with sub-088 condition task-milkshakeD, passing...\n",
      "[INFO] completed process.\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] making subject condition files from rois.\")\n",
    "\n",
    "for subject_id in subject_ids:\n",
    "    tasks=list(data_dict[subject_id].keys())\n",
    "    for task in tasks:\n",
    "        # get roi texts for subject / condition\n",
    "        roi_txts = glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/%s_%s*txt'%(subject_id,task))\n",
    "        df_lst=[]\n",
    "        for txt in roi_txts: \n",
    "            #print(txt)\n",
    "            df_temp = pd.read_csv(txt, sep=\"\\n\", header=None)\n",
    "            #print(df_temp)\n",
    "            df_lst.append(df_temp)\n",
    "        try:\n",
    "            df_concat= pd.concat(df_lst, axis=1, sort=False)\n",
    "            #print(df_concat)\n",
    "\n",
    "            # write output file \n",
    "            outfile='/projects/niblab/experiments/chocolate_milkshake/data/betaseries/by_sub/%s_%s.txt'%(subject_id,task)\n",
    "            #print('[INFO] making file %s'%outfile)\n",
    "            df_concat.to_csv(outfile, header=None, index=None, sep='\\t')\n",
    "        except:\n",
    "            print('[INFO]error with %s condition %s, passing...'%(subject_id,task))\n",
    "print(\"[INFO] completed process.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qucikly view the created files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-146_task-milkshakeB.txt',\n",
       " 'sub-146_task-milkshakeA.txt',\n",
       " 'sub-147_task-milkshakeB.txt',\n",
       " 'sub-147_task-milkshakeA.txt',\n",
       " 'sub-150_task-milkshakeC.txt',\n",
       " 'sub-150_task-milkshakeB.txt',\n",
       " 'sub-151_task-milkshakeC.txt',\n",
       " 'sub-151_task-milkshakeB.txt',\n",
       " 'sub-154_task-milkshakeC.txt',\n",
       " 'sub-154_task-milkshakeA.txt']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/by_sub')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(subj_id, subj_condition)\n",
    "# go through rois\n",
    "for index in roi_df.index.values:\n",
    "    #print(index)\n",
    "    roi = index\n",
    "    x = roi_df.loc[index, \"MNI_x\"]\n",
    "    y = roi_df.loc[index, \"MNI_y\"]\n",
    "    z = roi_df.loc[index, \"MNI_z\"]\n",
    "    #print(roi,x,y,z)\n",
    "    out_path = os.path.join(out_dir, \"{}_{}_{}.txt\".format(subj_id, subj_condition, roi))\n",
    "    #print(\"Output file being made: {}\".format(out_path))\n",
    "    cmd='fslmeants -i {} -o {} -c {} {} {} --usemm \\n\\n'.format(nifti, out_path, x, y, z)\n",
    "\n",
    "    #print(\"Running shell command: {}\".format(cmd))\n",
    "    subprocess.run(cmd, shell=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
