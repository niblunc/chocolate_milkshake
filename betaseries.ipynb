{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import subprocess\n",
    "import re\n",
    "from IPython.core import display as ICD\n",
    "from os import listdir\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from shutil import rmtree\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chocolate Milkshake Betaseries \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Conents:\n",
    "\n",
    "* [FSL feat1 analysis](#second-bullet)  \n",
    "* [Concatenate with fslmerge](#third-bullet)\n",
    "* [Transform functionals with flirt and fslmath](#fourth-bullet)\n",
    "* [Pull individual ROI timeseries by subject](#fifth-bullet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Paradigm**\n",
    "\n",
    "Functional Tasks: \n",
    "\n",
    "    milkshake pic, milkshake receipt, h20 pic, h20 receipt, milkshake minus h20, milkshake plus h20, rinse\n",
    "\n",
    "Furthermore, `milkshake` is broken down into the following specifities:   \n",
    "      \n",
    "    HF(high fat, HS(high sugar), and respectively, LF(low fat), LS(low sugar)   \n",
    "\n",
    "with the following relationships:  \n",
    "    \n",
    "    HF_HS, HF_LS, LF_HS, LF_LS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Variables**  \n",
    "Set common variable paths, such as the betaseries output folder, the study folder, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View if any tasks are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.system('echo ${FSLDIR}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/projects/niblab/experiments/chocolate_milkshake/data'\n",
    "beta_series_path='projects/niblab/experiments/chocolate_milkshake/data/betaseries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_path='/projects/niblab/experiments/chocolate_milkshake/data/betaseries'\n",
    "concat_path=\"/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat\"\n",
    "keyword=\"LF_HS_minus_h20\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EV path: /projects/niblab/experiments/chocolate_milkshake/data/onsets/milkshake\n",
      "[INFO] Beta series analysis output path: projects/niblab/experiments/chocolate_milkshake/data/betaseries\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] EV path: {}'.format('/projects/niblab/experiments/chocolate_milkshake/data/onsets/milkshake'))\n",
    "\n",
    "print('[INFO] Beta series analysis output path: {}'.format(beta_series_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] trial feat folders available, per subject\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['design_files',\n",
       " 'sub-154_ses-1_mkC_HF_HS_receipt_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_HF_LS_receipt_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_receipt_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_HF_LS_receipt_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_LF_LS_receipt_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_HF_LS_receipt_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_LF_LS_receipt_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_receipt_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_receipt_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_LF_LS_receipt_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_h20_receipt_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_receipt_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_h20_receipt_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_h20_receipt_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial4.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial5.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial6.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial7.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial8.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial9.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial4.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial6.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial5.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial4.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial5.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial6.feat']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view directory contents\n",
    "print(\"[INFO] trial feat folders available, per subject\")\n",
    "listdir(os.path.join(data_path, 'bids/derivatives/preprocessed/sub-154/ses-1/analysis/beta/task-milkshakeC'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiprocessing Helper Function**  \n",
    "Common functions used throughout the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunks(l,n):\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSL feat1 analysis <a class='anchor' id='second-bullet'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the functional tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] set of unique chocolate evs: \n",
      " {'h20_receipt', 'h20_pic', 'LF_LS_receipt', 'LF_HS_minus_h20', 'HS_plus_h20', 'HF_LS_receipt', 'milkshake_pic', 'HF_HS_receipt', 'HF_HS_minus_h20', 'LF_HS_receipt', 'rinse'}\n"
     ]
    }
   ],
   "source": [
    "choco_ev_files=glob.glob('/projects/niblab/data/eric_data/ev_files/milkshake/*.ev')\n",
    "choco_evs=[x.split('/')[-1].replace('.ev',\"\") for x in choco_ev_files]\n",
    "choco_evs=[re.sub('mk[A-Z]_', '',x) for x in choco_evs]\n",
    "choco_evs=set(choco_evs)\n",
    "print(\"[INFO] set of unique chocolate evs: \\n\", choco_evs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob('/projects/niblab/data/eric_data/ev_files/milkshake/mkA*'):\n",
    "    #print(file)\n",
    "    df_temp=pd.read_csv(file, header=None)\n",
    "    #ICD.display(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Do we want to collapse any trials(evs)?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make subject condition feat files (`.fsf`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View fsf files currently available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['design_files',\n",
       " 'sub-154_ses-1_mkC_HF_HS_receipt_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_HF_LS_receipt_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_receipt_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_HF_LS_receipt_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_LF_LS_receipt_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_HF_LS_receipt_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_LF_LS_receipt_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_receipt_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_receipt_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_LF_LS_receipt_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_h20_receipt_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_receipt_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_h20_receipt_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_h20_receipt_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial4.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial5.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial6.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial7.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial8.feat',\n",
       " 'sub-154_ses-1_mkC_HS_plus_h20_trial9.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial4.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial6.feat',\n",
       " 'sub-154_ses-1_mkC_HF_HS_minus_h20_trial5.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial1.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial2.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial3.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial4.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial5.feat',\n",
       " 'sub-154_ses-1_mkC_LF_HS_minus_h20_trial6.feat']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir(os.path.join(data_path, 'bids/derivatives/preprocessed/sub-154/ses-1/analysis/beta/task-milkshakeC'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file(sub_id, ses_id, trial_id, output_dir, task,data_dict):\n",
    "    with open(os.path.join('/projects/niblab/experiments/chocolate_milkshake/data/code/beta_design.fsf'),'r') as infile:\n",
    "        tempfsf=infile.read()\n",
    "        #\n",
    "        if not os.path.exists(os.path.join(output_dir, \"design_files\")):\n",
    "            os.makedirs(os.path.join(output_dir, \"design_files\"))\n",
    "        #print(output_dir)\n",
    "        design_fileout = os.path.join(output_dir, \"design_files/%s_%s_%s_feat1.fsf\"%(sub_id, ses_id, trial_id))\n",
    "        out_param = data_dict[sub_id][task][\"TRIALS\"][\"TRIAL%s\"%trial_id][\"OUTPUT\"]\n",
    "        func_param = data_dict[sub_id][task][\"FUNCRUN\"]\n",
    "        confound_param = data_dict[sub_id][task][\"CONFOUND\"]\n",
    "        trial_param = data_dict[sub_id][task][\"TRIALS\"][\"TRIAL%s\"%trial_id][\"TRIAL\"]\n",
    "        nuis_param = data_dict[sub_id][task][\"TRIALS\"][\"TRIAL%s\"%trial_id][\"NUIS\"]\n",
    "\n",
    "        tempfsf = tempfsf.replace(\"OUTPUT\", out_param)\n",
    "        tempfsf = tempfsf.replace(\"FUNCRUN\", func_param) \n",
    "        tempfsf = tempfsf.replace(\"CONFOUND\", confound_param)\n",
    "        tempfsf = tempfsf.replace(\"TRIAL\", trial_param)\n",
    "        tempfsf = tempfsf.replace(\"NUIS\", nuis_param)\n",
    "\n",
    "        for i in range(6):\n",
    "            moco = data_dict[sub_id][task][\"MOCO%i\"%i]\n",
    "            tempfsf = tempfsf.replace(\"MOCO%i\"%i, moco)\n",
    "        try:\n",
    "            with open(design_fileout,'w') as outfile:\n",
    "                outfile.write(tempfsf)\n",
    "            outfile.close()\n",
    "        except:\n",
    "            print(\"BAD SUBJECT \", sub_id)\n",
    "        infile.close()\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fsf(input_dir, deriv_path, ses_id):\n",
    "    orig_path='/projects/niblab/bids_projects/Experiments/ChocoData/derivatives'\n",
    "    ses_id=ses_id\n",
    "    data_dict= {}\n",
    "    # start loop -- looping through subjects\n",
    "    subject_list = glob.glob(os.path.join(deriv_path, 'preprocessed', 'sub-*/%s'%ses_id))\n",
    "    for sub_path in sorted(subject_list):\n",
    "        #print(sub_path)\n",
    "        sub_id=sub_path.split(\"/\")[-2]\n",
    "        functional_tasks = glob.glob(os.path.join(orig_path,'%s/ses-1'%sub_id, 'func/*milkshake*preproc_brain.nii.gz'))\n",
    "        if sub_id not in data_dict:\n",
    "            data_dict[sub_id] = {}\n",
    "                \n",
    "        \n",
    "        for functional in functional_tasks: # SECOND LOOP -- looping through RUNS\n",
    "            #print(sub_id)\n",
    "            task=functional.split(\"/\")[-1].split(\"_\")[2].split(\"-\")[1]\n",
    "            #print(task)\n",
    "            analysis_folder=os.path.join(deriv_path, 'preprocessed/%s/%s'%(sub_id,ses_id), \"analysis\")\n",
    "            #print(analysis_folder)\n",
    "            output_dir = os.path.join(analysis_folder, 'beta/task-%s'%task)\n",
    "            \n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            \n",
    "            confound_file = os.path.join(orig_path, \"%s/ses-1\"%sub_id, \"func/motion_assessment/%s_%s_task-%s_bold_space-MNI152NLin2009cAsym_preproc_brain_confound.txt\"%(sub_id,ses_id, task))\n",
    "                \n",
    "            data_dict[sub_id][task] = {\n",
    "                \"TRIALS\" : { },\n",
    "                \"CONFOUND\" : confound_file,\n",
    "                \"FUNCRUN\" : functional\n",
    "              }           \n",
    "            \n",
    "            for i in range(6):\n",
    "                motcor=os.path.join(orig_path, \"%s/ses-1\"%sub_id, 'func','motion_assessment', 'motion_parameters','%s_%s_task-%s_moco%s.txt'%(sub_id,ses_id, task,i))\n",
    "                data_dict[sub_id][task]['MOCO%i'%i] = motcor\n",
    "            \n",
    "            \n",
    "            subj_trials = sorted(glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/evs/trials/%s*trial*.txt'%task.replace('milkshake', 'mk')))\n",
    "            \n",
    "            #print(subj_trials)\n",
    "            \n",
    "            \n",
    "            if not subj_trials:\n",
    "                pass\n",
    "            else:\n",
    "                for trial_file in subj_trials:\n",
    "                    _id = sub_id.split(\"-\")[1]\n",
    "                    _id = _id[1:]\n",
    "                    trial_id = trial_file.split(\"/\")[-1].split(\".\")[0]\n",
    "                    #print(trial_id)\n",
    "                    nuis_file = os.path.join('/projects/niblab/experiments/chocolate_milkshake/data/evs/nuis', '%s.txt'%trial_id.replace('trial', 'nuis'))\n",
    "                    #print(nuis_file)\n",
    "                    fileout = os.path.join(output_dir, \"%s_%s_%s\"%(sub_id, ses_id,trial_id))\n",
    "                    #print(fileout)\n",
    "                    data_dict[sub_id][task][\"TRIALS\"][\"TRIAL%s\"%trial_id] = {\"TRIAL\" : trial_file, \"NUIS\": nuis_file, \"OUTPUT\" : fileout}\n",
    "                    make_file(sub_id, ses_id, trial_id,output_dir, task, data_dict)\n",
    "                    \n",
    "    print(\"[INFO] completed making fsl feat1 files.\")               \n",
    "    return(data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] completed making fsl feat1 files.\n"
     ]
    }
   ],
   "source": [
    "def fsl_feat1():\n",
    "    deriv_path='/projects/niblab/experiments/chocolate_milkshake/data/bids/derivatives'\n",
    "    ses_id='ses-1'\n",
    "    input_dir = '/projects/niblab/experiments/chocolate_milkshake'\n",
    "    data_dict=create_fsf(input_dir, deriv_path,ses_id)\n",
    "    \n",
    "fsl_feat1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Slurm Jobs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '4', '5', '9', '11']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_list =  [x.split(\"/\")[-2].split(\"-\")[1].strip('0') for x in glob.glob(os.path.join('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives', 'sub-*/ses-1'))]\n",
    "subject_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slurm_by_file(subject,keyword):\n",
    "    fsfs=glob.glob(os.path.join('/projects/niblab/experiments/chocolate_milkshake/data/bids/derivatives/preprocessed/{}/ses-1/analysis/beta/task*/design_files/*{}*.fsf'.format(subject, keyword)))\n",
    "    for fsf in fsfs:\n",
    "        slurm_cmd = \"sbatch /projects/niblab/experiments/chocolate_milkshake/data/code/beta_by_file.job {}\".format(fsf)\n",
    "        #print('[INFO] submitted: \\n', slurm_cmd)\n",
    "        #os.system(slurm_cmd)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit slurm jobs by running fsf files individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] submitted slurm jobs.\n"
     ]
    }
   ],
   "source": [
    "subject_ids=[x.split('/')[-2] for x in glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/bids/derivatives/preprocessed/*/ses-1')]\n",
    "keyword=\"pic\"\n",
    "for subject in subject_ids:\n",
    "    #print(subject)\n",
    "    slurm_by_file(subject, keyword)\n",
    "\n",
    "print('[INFO] submitted slurm jobs.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n"
     ]
    }
   ],
   "source": [
    "!squeue -u nbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listdir('/projects/niblab/experiments/chocolate_milkshake/data/bids/derivatives/preprocessed/sub-113/ses-1/analysis/beta/task-milkshakeB')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and set variables\n",
    "beta_path='/projects/niblab/experiments/chocolate_milkshake/data/betaseries'\n",
    "concat_path=\"/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat\"\n",
    "subject_folders=sorted(glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/bids/derivatives/preprocessed/sub-*'))\n",
    "\n",
    "data_dict={}\n",
    "bad_subs=[]\n",
    "\n",
    "for folder in subject_folders:\n",
    "    subject_id=folder.split(\"/\")[-1]\n",
    "    #print(os.path.join(folder,'ses-1/analysis/beta/*.feat'))\n",
    "    tasks=glob.glob(os.path.join(folder,'ses-1/analysis/beta/*'))\n",
    "    #print(tasks)\n",
    "    if not tasks:\n",
    "        bad_subs.append(subject_id)\n",
    "    else:\n",
    "        if subject_id not in data_dict:\n",
    "            data_dict[subject_id]={}\n",
    "        for task_folder in tasks:\n",
    "            #print(task_folder)\n",
    "            task=task_folder.split(\"/\")[-1].split('.')[0]\n",
    "            #print(task)\n",
    "            if task not in data_dict[subject_id]:\n",
    "                data_dict[subject_id][task]={}\n",
    "            pes=glob.glob(os.path.join(task_folder, '*.feat'))\n",
    "            data_dict[subject_id][task]=pes\n",
    "       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in data_dict:\n",
    "    #print(\"[INFO] \", subject)\n",
    "    for task in data_dict[subject]:\n",
    "        #print(\"[INFO] \", task)\n",
    "        dir_ct=0\n",
    "        \n",
    "        \n",
    "        for directory in data_dict[subject][task]:\n",
    "            \n",
    "            if \"minus\" in directory:\n",
    "                dir_ct+=1\n",
    "        if dir_ct < 9:\n",
    "            print(\"[INFO] %s %s\"%( subject, task))\n",
    "            print(dir_ct)\n",
    "        #print(dir_ct)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate (fslmerge) data <a class='anchor' id='third-bullet'></a>  \n",
    "`fslmerge : concatente image files into a single output.`   \n",
    "  \n",
    "In this step we use the `fslmerge` command to combine the `pe.nii.gz` files by subject of the same condition.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_files(subject_list, data_dict=data_dict,keyword=keyword):\n",
    "\n",
    "    for subject_id in subject_list:\n",
    "        for task in data_dict[subject_id]:\n",
    "            #print(task)\n",
    "            feat_path='/projects/niblab/experiments/chocolate_milkshake/data/bids/derivatives/preprocessed/%s/ses-1/analysis/beta/%s/*%s*.feat/stats/pe1.nii.gz'%(subject_id, task, keyword)\n",
    "            pes=glob.glob(os.path.join(feat_path))\n",
    "            #print(pes)\n",
    "            #print(trial)\n",
    "            #filename=trial.replace(subject_id+\"_\", \"\")\n",
    "            extension=task+\"_%s\"%keyword\n",
    "            outfile = os.path.join(concat_path, \"%s/%s_%s\"%(keyword, subject_id, extension))\n",
    "            #print(outfile)\n",
    "            if not pes:\n",
    "                bad_subs.append(subject_id)\n",
    "            else:\n",
    "                pe_str = \" \".join(pes)\n",
    "                fslmerge_cmd=\"/projects/niblab/modules/software/fsl/5.0.10/bin/fslmerge -t %s %s\"%(outfile, pe_str)\n",
    "                #print(\"[INFO] running fsl merge command...\")\n",
    "                #print(fslmerge_cmd, \"\\n\")\n",
    "                #os.system(fslmerge_cmd)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] chunksize: 10\n",
      "[INFO] running fslmerge ....\n",
      "fslmerge -t [OUTPUT FILENAME][PE FILES]\n",
      "[INFO] process complete.\n",
      "[INFO] find images here:  /projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat\n"
     ]
    }
   ],
   "source": [
    "chunksize=10\n",
    "print(\"[INFO] chunksize: {}\".format(chunksize))\n",
    "chunk_list=chunks(subject_ids, chunksize)\n",
    "\n",
    "#print(chunk_list)\n",
    "print(\"[INFO] running fslmerge ....\\nfslmerge -t [OUTPUT FILENAME][PE FILES]\")\n",
    "\n",
    "with Pool(5) as p:\n",
    "    p.map(merge_files, chunk_list)\n",
    "print(\"[INFO] process complete.\")\n",
    "print('[INFO] find images here: ',concat_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Functionals (flirt & fslmaths) <a class='anchor' id='fourth-bullet'></a> \n",
    "To use the BigBrain300 rois we need to transform the nifti task files to match the mask.\n",
    "ROIs location on renci: `/projects/niblab/parcellations/chocolate_decoding_rois`   \n",
    "\n",
    "Big Brain 300: `/projects/niblab/parcellations/chocolate_decoding_rois/old_rois/bigBrain300_atlas`\n",
    "  \n",
    "`flirt`: the main program that performs affine registration. The options we use here:  \n",
    "* `-in`, an input  \n",
    "* `-ref`, a reference volume  \n",
    "* `applyxfm`, `-init` and `-out`, apply a saved transformation to a volume   \n",
    "\n",
    "  \n",
    "  \n",
    "*For these usages the reference volume must still be specified as this sets the voxel and image dimensions of the resulting volume.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] transform afunctionals to match the mask.\n",
      "[INFO] transformation process complete.\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] transform functionals to match the mask.')\n",
    "\n",
    "reference_nifti='/projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.nii.gz'\n",
    "reference_mat='/projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.mat'\n",
    "for nii in fslmerged_files:\n",
    "    \n",
    "    # setup and run flirt\n",
    "    nii=nii.replace('.nii.gz', '')\n",
    "    out=nii+'_3mm'\n",
    "    flirt_cmd=\"flirt -in {} -ref {} -init {} -applyxfm -out {}\".format(nii, reference_nifti, reference_mat, out)\n",
    "    #print('[INFO] flirt command: \\n{}'.format(flirt_cmd))\n",
    "    #os.system(flirt_cmd)\n",
    "    \n",
    "    fslmaths_cmd='fslmaths {} -thr 0.9 {}'.format(out,out)\n",
    "    #print('[INFO] fslmaths command: \\n{}'.format(fslmaths_cmd))\n",
    "    #os.system(fslmaths_cmd)\n",
    "    \n",
    "print('[INFO] transformation process complete.')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranform_niftis(niftis, keyword=keyword):\n",
    "    reference_nifti='/projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.nii.gz'\n",
    "    reference_mat='/projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.mat'\n",
    "    for nii in niftis:\n",
    "\n",
    "        # setup and run flirt\n",
    "        nii=nii.replace('.nii.gz', '')\n",
    "        out=nii+'_3mm'\n",
    "        flirt_cmd=\"flirt -in {} -ref {} -init {} -applyxfm -out {}\".format(nii, reference_nifti, reference_mat, out)\n",
    "        #print('[INFO] flirt command: \\n{}'.format(flirt_cmd))\n",
    "        #os.system(flirt_cmd)\n",
    "\n",
    "        fslmaths_cmd='fslmaths {} -thr 0.9 {}'.format(out,out)\n",
    "        #print('[INFO] fslmaths command: \\n{}'.format(fslmaths_cmd))\n",
    "        #os.system(fslmaths_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] transform functionals to match the mask.\n",
      "[INFO] chunksize: 10\n",
      "[INFO] transformation process complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('[INFO] transform functionals to match the mask.')\n",
    "chunksize=10\n",
    "# grab concatenated (fslmerge) data\n",
    "keyword=\"LF_HS_minus_h20\"\n",
    "fslmerged_files=glob.glob(os.path.join(concat_path,'%s/*%s*.nii.gz'%(keyword,keyword)))\n",
    "#fslmerged_files[:4]\n",
    "print(\"[INFO] chunksize: {}\".format(chunksize))\n",
    "chunk_list=chunks(fslmerged_files, chunksize)\n",
    "with Pool(5) as p:\n",
    "    p.map(tranform_niftis, chunk_list)\n",
    "print('[INFO] transformation process complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View fslmerge niftis avaiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HF_HS_minus_h20', 'HS_plus_h20', 'LF_HS_minus_h20', 'milkshake_receipt']\n"
     ]
    }
   ],
   "source": [
    "stim_list=listdir(os.path.join(concat_path ))#keyword))\n",
    "print(stim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] STIMULUS: HF_HS_minus_h20 (227 files) \n",
      "[INFO] STIMULUS: HS_plus_h20 (227 files) \n",
      "[INFO] STIMULUS: LF_HS_minus_h20 (227 files) \n",
      "[INFO] STIMULUS: milkshake_receipt (224 files) \n"
     ]
    }
   ],
   "source": [
    "for stim in stim_list:\n",
    "    print(\"[INFO] STIMULUS: %s (%s files) \"%(stim,len(listdir(os.path.join(concat_path, stim)))))\n",
    "    #print(sorted(listdir(os.path.join(concat_path, stim))[-2:]))\n",
    "    \n",
    "    #get subjects \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull ROI timeseries  <a class='anchor' id='fifth-bullet'></a>\n",
    "\n",
    "Pull individual rois timeseries for each subject. \n",
    "\n",
    "Example command:  \n",
    "\n",
    "\n",
    "    fslmeants -i ~/sub-001_punish.nii.gz -o ~/3_pull_timeseries/sub-001_punish_AI_35_23_-6_asymPREPspace.nii.gz.txt -m ~/AI_35_23_-6_asymPREPspace.nii.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def pull_timeseries(roi_list, bb300_path='/projects/niblab/parcellations/bigbrain300',roi_df='/projects/niblab/parcellations/bigbrain300/renaming.csv'):\n",
    "\n",
    "    \n",
    "    bad_subs=[]\n",
    "    #ICD.display(roi_df)\n",
    "\n",
    "    # load asymmetrical nifti roi files\n",
    "    asym_niftis=glob.glob(\"/projects/niblab/parcellations/bigbrain300/MNI152Asymmetrical_3mm/*.nii.gz\")\n",
    "\n",
    "    # load roi list\n",
    "    out_dir = os.path.join(beta_path, 'rois/big300')\n",
    "    #print('[INFO] OUT DIRECTORY: %s \\n'%out_dir)\n",
    "\n",
    "    #roi_df.set_index(\"final order name\", inplace=True)\n",
    "    #ICD.display(roi_df)#.head())\n",
    "\n",
    "    # run parallel job pools\n",
    "\n",
    "\n",
    "    # loop through the roi file list\n",
    "    #print(roi_list[:3])\n",
    "    for nifti in sorted(roi_list):\n",
    "        #print('[INFO] loop1')\n",
    "        #print(nifti)\n",
    "        subj_id = nifti.split(\"/\")[-1].split(\"_\")[0]\n",
    "        subj_condition=nifti.split(\"/\")[-1].split(\".\")[0].replace(\"_3mm\", \"\")\n",
    "        #print('[INFO] roi: %s %s'%(subj_id, subj_condition))\n",
    "\n",
    "        # loop through roi reference list\n",
    "        for ref_nifti in sorted(asym_niftis):\n",
    "            #print('[INFO] reference roi: %s'%ref_nifti)\n",
    "            roi = ref_nifti.split('/')[-1].split(\".\")[0]\n",
    "            out_path = os.path.join(out_dir, \"{}_{}.txt\".format(subj_condition, roi))\n",
    "            #print(roi, out_path)\n",
    "            cmd='fslmeants -i {} -o {} -m {}'.format(nifti, out_path, ref_nifti)\n",
    "            try:\n",
    "                #cmd='fslmeants -i {} -o {} -m {}'.format(nifti, out_path, ref_nifti)\n",
    "                #print(\"Running shell command: {}\".format(cmd))\n",
    "                os.system(cmd)\n",
    "            except:\n",
    "                bad_subs.append((subj_id, subj_condition))\n",
    "        \n",
    "        #print('[INFO] finished processing for %s'%subj_id)\n",
    "        \n",
    "\n",
    "    return \"%s\"%bad_subs\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading roi and reference file....\n",
      "[INFO] 6 task roi nifti files being processed.\n",
      "[INFO] chunksize: 6\n",
      "[INFO] starting multiprocess...\n",
      "[INFO] process complete. \n",
      "[INFO] bad subjects: \t\t['[]']\n"
     ]
    }
   ],
   "source": [
    "stim='HS_plus_h20'\n",
    "\n",
    "# load roi\n",
    "print(\"[INFO] loading roi and reference file....\")\n",
    "\n",
    "# task rois loaded\n",
    "task_rois=sorted(glob.glob(os.path.join(concat_path,stim,'*sub-*_3mm.nii.gz')))\n",
    "#print(task_rois[:5])\n",
    "print(\"[INFO] {} task roi nifti files being processed.\".format(len(task_rois)))\n",
    "\n",
    "chunksize=6\n",
    "print(\"[INFO] chunksize: {}\".format(chunksize))\n",
    "chunk_list=chunks(task_rois, chunksize)\n",
    "#roi_df['network']\n",
    "# pull timeseries by rois --fslmeants command\n",
    "\n",
    "def run_process(pool_size):\n",
    "    print(\"[INFO] starting multiprocess...\")\n",
    "    with Pool(pool_size) as p:\n",
    "        error_subjects=p.map(pull_timeseries, chunk_list)\n",
    "    print(\"[INFO] process complete. \\n[INFO] bad subjects: \\t\\t%s\"%error_subjects)\n",
    "    \n",
    "pool_size=15\n",
    "run_process(pool_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submit process as a batch job for large datasets**  \n",
    "\n",
    "Two files:  \n",
    "- timeseries_pull.job  \n",
    "- timeseries_pull.py  \n",
    "\n",
    "*quick view of file contents below* -- note,for now paths may need to be updated directly in the scripts for your unqiue setup, flexible script in progress.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat /projects/niblab/experiments/chocolate_milkshake/data/code/timeseries_pull.job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat /projects/niblab/experiments/chocolate_milkshake/data/code/timeseries_pull.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit job file:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3185256\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch /projects/niblab/experiments/chocolate_milkshake/data/betaseries/timeseries_roi_pull.job HF_HS_minus_h20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "           3185256     batch timeseri   nbytes  R    3:23:16      1 largemem-0-0\r\n"
     ]
    }
   ],
   "source": [
    "!squeue --job 3185256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3185257\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch /projects/niblab/experiments/chocolate_milkshake/data/betaseries/timeseries_roi_pull.job LF_HS_minus_h20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "           3185257     batch timeseri   nbytes  R    3:01:55      1 largemem-0-0\r\n"
     ]
    }
   ],
   "source": [
    "!squeue --job 3185257\n",
    "#!squeue -u nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get timeseries roi task files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HS_plus_h20',\n",
       " 'h2O_pic',\n",
       " 'milkshake_pic',\n",
       " 'rinse',\n",
       " 'LF_HS_minus_h20',\n",
       " 'HF_HS_minus_h20',\n",
       " 'milkshake_receipt']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view timeseries \n",
    "listdir('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at single file contents:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.305654261  \r\n",
      "22.92921219  \r\n",
      "2.180785209  \r\n",
      "7.329646152  \r\n",
      "1.913219816  \r\n",
      "12.33518228  \r\n",
      "1.481388868  \r\n",
      "26.48972737  \r\n",
      "7.085836688  \r\n",
      "15.88141086  \r\n",
      "21.39033703  \r\n",
      "17.30740555  \r\n",
      "9.705909108  \r\n",
      "49.65908761  \r\n",
      "2.668380528  \r\n",
      "2.808356385  \r\n",
      "87.48411054  \r\n",
      "104.7683015  \r\n",
      "13.93522501  \r\n",
      "36.65064512  \r\n",
      "14.73222093  \r\n",
      "63.62429159  \r\n",
      "621.9953755  \r\n",
      "3206.146965  \r\n",
      "2860.557884  \r\n",
      "2922.173812  \r\n",
      "930.39091  \r\n",
      "4743.002419  \r\n"
     ]
    }
   ],
   "source": [
    "#/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300/milkshake_receipt/sub-049_task-milkshakeC_bb300_MNI152Asymm3mm_001.txt\n",
    "\n",
    "!cat /projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300/milkshake_receipt/sub-049_task-milkshakeC_bb300_MNI152Asymm3mm_001.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] HF_HS_minus_h20 (0 files)\n",
      "[INFO] HS_plus_h20 (62629 files)\n",
      "[INFO] LF_HS_minus_h20 (0 files)\n",
      "[INFO] milkshake_receipt (67200 files)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# view number of subject timeseries rois created/pulled\n",
    "for stim in stim_list:\n",
    "    print(\"[INFO] %s (%s files)\"%(stim, \n",
    "                                  len(glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300/%s/*.txt'%stim))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Timeseries into Matrix  <a class=\"anchor\" id=\"sixth-bullet\"></a>\n",
    "Combine timeseries roi files into, **one file per condition per participant**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-150', 'sub-151', 'sub-154']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_ids=list(data_dict.keys())\n",
    "subject_ids[-3:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through subject ids and combine in matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subject_matrices(subjects):\n",
    "    for subject_id in subjects:\n",
    "        tasks=list(data_dict[subject_id].keys())\n",
    "        for task in tasks:\n",
    "\n",
    "            # get roi texts for subject / condition\n",
    "            roi_txts = glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300/%s_%s*txt'%(subject_id,task))\n",
    "            df_lst=[]\n",
    "            for txt in roi_txts: \n",
    "                #print(txt)\n",
    "                df_temp = pd.read_csv(txt, sep=\"\\n\", header=None)\n",
    "                #print(df_temp)\n",
    "                df_lst.append(df_temp)\n",
    "            try:\n",
    "                df_concat= pd.concat(df_lst, axis=1, sort=False)\n",
    "                #print(df_concat)\n",
    "\n",
    "                # write output file \n",
    "                outfile='/projects/niblab/experiments/chocolate_milkshake/data/betaseries/subject_matrices/%s_%s-receipt.txt'%(subject_id,task)\n",
    "                #print('[INFO] making file %s'%outfile)\n",
    "                #df_concat.to_csv(outfile, header=None, index=None, sep='\\t')\n",
    "            except:\n",
    "                print('[INFO]error with %s condition %s, passing...'%(subject_id,task))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing 12 lists\n"
     ]
    }
   ],
   "source": [
    "roi_txts = glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300/%s_%s*txt'%(subject_id,task))\n",
    "outfile='/projects/niblab/experiments/chocolate_milkshake/data/betaseries/subject_matrices/%s_%s.txt'%(subject_id,task)\n",
    "\n",
    "subject_chunks=chunks(subject_ids, 10)\n",
    "#subject_chunks[:2]\n",
    "\n",
    "print(\"[INFO] processing %s lists\"%len(subject_chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run parallel process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] making subject condition matrix from rois timeseries...\n",
      "[INFO]error with sub-088 condition task-milkshakeD, passing...\n",
      "[INFO]error with sub-032 condition task-milkshakeD, passing...\n",
      "[INFO]error with sub-033 condition task-milkshakeC, passing...\n",
      "[INFO]error with sub-015 condition task-milkshakeC, passing...\n",
      "[INFO]error with sub-081 condition task-milkshakeC, passing...\n",
      "[INFO] completed process.\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] making subject condition matrix from rois timeseries...\")\n",
    "\n",
    "with Pool(10) as p:\n",
    "    p.map(create_subject_matrices, subject_chunks)\n",
    "    \n",
    "print(\"[INFO] completed process.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick view of new files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-142_task-milkshakeB-receipt.txt',\n",
       " 'sub-143_task-milkshakeC-receipt.txt',\n",
       " 'sub-143_task-milkshakeA-receipt.txt',\n",
       " 'sub-144_task-milkshakeD-receipt.txt',\n",
       " 'sub-144_task-milkshakeA-receipt.txt']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/subject_matrices')[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/subject_matrices/*.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
