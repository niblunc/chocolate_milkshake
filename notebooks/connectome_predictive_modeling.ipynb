{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectome Based Predictive Modeling on Chocolate Milkshake Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c anaconda seaborn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os, glob\n",
    "from nilearn.plotting import plot_connectome\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn import plotting\n",
    "from IPython.core import display as ICD\n",
    "from os import listdir\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fc matrices\n",
    "\"\"\"\n",
    "  Takes timeseries matrices and makes functional connectivity matrices with nilearns ConnectivityMeasure object.\n",
    "  We pass a condition, or named here the 'file_suffix', to identify our individual task files,\n",
    "  and we pass the number of extracted regions.\n",
    "  Outputs: makes subject FCMs, plots FCMs\n",
    "  Returns: a function correlation dictionary as well as individual subject list\n",
    "\n",
    "  ** Extensions: plotting, save individual FCMs...\n",
    "\"\"\"\n",
    "def makeFCM(cmap, timeseries=None, n_regions_extracted=28, file_suffix=\"reward\", functionals=None):\n",
    "  #print('[INFO] making functional connectivity matrices with nilearn ConnectivityMeasure object...')\n",
    "  fc_corr_dict = {}\n",
    "  subj_list=[]\n",
    "  correlations = []\n",
    "  # Initializing ConnectivityMeasure object with kind='correlation'\n",
    "  connectome_measure = ConnectivityMeasure(kind='correlation')\n",
    "  for subj_timeseries in sorted(timeseries):\n",
    "    subj_id=subj_timeseries.split(\"/\")[-1].split(\"_\")[0]\n",
    "    if subj_id not in fc_corr_dict:\n",
    "      fc_corr_dict[subj_id] = {}\n",
    "    if subj_id not in subj_list:\n",
    "      subj_list.append(subj_id)\n",
    "    if file_suffix in subj_timeseries:\n",
    "      filename = \"%s_%s.txt\"%(subj_id, file_suffix)\n",
    "      # we load the text file timeseries into an array \n",
    "      np_arr = np.loadtxt(subj_timeseries)\n",
    "      # call fit_transform from ConnectivityMeasure object\n",
    "      correlation = connectome_measure.fit_transform([np_arr])\n",
    "      # saving each subject correlation to correlations\n",
    "      fc_corr_dict[subj_id][file_suffix] = correlation\n",
    "      correlations.append(correlation)\n",
    "      \n",
    "      # plot subject correlation matrix\n",
    "      sns.heatmap(correlation, annot=True)\n",
    "\n",
    "      # save text\n",
    "      #np.savetxt('/content/'+filename, correlation.transpose(2,0,1).reshape(3,-1))\n",
    "\n",
    "    # Mean of all correlations\n",
    "  mean_correlations = np.mean(correlations, axis=0).reshape(n_regions_extracted, n_regions_extracted)\n",
    "\n",
    "\n",
    "\n",
    "  ## plotting\n",
    "  print('[INFO] Plot of the mean functional connectivity matrix: \\n')\n",
    "  title = 'Correlation between %d regions, condition %s'%(n_regions_extracted, condition)\n",
    "  # First plot the matrix\n",
    "  display = plotting.plot_matrix(mean_correlations, vmax=1, vmin=-1, colorbar=True, title=title, cmap=cmap)\n",
    "  plt.show()\n",
    "  print(\"\\n\\n\")\n",
    "  # Then find the center of the regions and plot a connectome\n",
    "  #regions_img = regions_extracted_img\n",
    "  #coords_connectome = plotting.find_probabilistic_atlas_cut_coords(regions_img)\n",
    "\n",
    "  #plotting.plot_connectome(mean_correlations, coords_connectome,\n",
    "                          #edge_threshold='90%', title=title)\n",
    "        \n",
    "  return fc_corr_dict, subj_list;\n",
    "\n",
    "def read_in_matrices(subj_list, fc_corr_dict, file_suffix=None, data_dir=\"/\", zscore=False):\n",
    "    \"\"\"\n",
    "    Reads in a set of individual-subject connectivity matrices stored in data_dir,\n",
    "    \n",
    "    Returns a dataframe that is subjects x edges (by vectorizing the upper triangle of each FC matrix).\n",
    "    \n",
    "    Assumes:\n",
    "    - each matrix is stored in a separate file beginning with the subject ID, and\n",
    "    - matrices are symmetric (squareform); i.e., for a parcellation with 268 nodes, matrices should be 268 x 268\n",
    "    \"\"\"\n",
    "    \n",
    "    all_fc_data = {}\n",
    "            \n",
    "    for subj in subj_list:\n",
    "        # try to find this subject's matrix\n",
    "        try:\n",
    "          if file_suffix:\n",
    "              # make list files found\n",
    "              matrix = fc_corr_dict[subj][file_suffix]\n",
    "            #file = [f for f in matrices if subj in f and file_suffix in f]\n",
    "        #else:\n",
    "            #file = [f for f in matrices if subj in f]\n",
    "        except:\n",
    "          pass    \n",
    "        # make sure there is one and only one file    \n",
    "        #if len(file) ==0:\n",
    "            #raise ValueError(\"No data found for subject {}\".format(subj))\n",
    "        #if len(file) >1:\n",
    "            #raise ValueError(\"More than one matrix found for subject {}! Specify a suffix?\".format(subj))\n",
    "        \n",
    "        # read it in and make sure it's symmetric and has reasonable dimensions\n",
    "        tmp = matrix.transpose(2,0,1).reshape(28,-1)\n",
    "\n",
    "        assert tmp.shape[0]==tmp.shape[1]>1, \"Matrix seems to have incorrect dimensions: {}\".format(tmp.shape)\n",
    "        \n",
    "        # take just the upper triangle and store it in a dictionary\n",
    "        if ~zscore:\n",
    "            all_fc_data[subj] = tmp[np.triu_indices_from(tmp, k=1)]\n",
    "        if zscore:\n",
    "            all_fc_data[subj] = sp.stats.zscore(tmp[np.triu_indices_from(tmp, k=1)])\n",
    "        \n",
    "    # Convert dictionary into dataframe\n",
    "    all_fc_data = pd.DataFrame.from_dict(all_fc_data, orient='index')\n",
    "    #print('[INFO] made functional connectivity matrix dataframe.')\n",
    "\n",
    "\n",
    "    return all_fc_data\n",
    "\n",
    "def mk_kfold_indices(subj_list, k):\n",
    "    \"\"\"\n",
    "    Splits list of subjects into k folds for cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_subs = len(subj_list)\n",
    "    n_subs_per_fold = n_subs//k # floor integer for n_subs_per_fold\n",
    "\n",
    "    indices = [[fold_no]*n_subs_per_fold for fold_no in range(k)] # generate repmat list of indices\n",
    "    remainder = n_subs % k # figure out how many subs are left over\n",
    "    remainder_inds = list(range(remainder))\n",
    "    indices = [item for sublist in indices for item in sublist]    \n",
    "    [indices.append(ind) for ind in remainder_inds] # add indices for remainder subs\n",
    "\n",
    "    assert len(indices)==n_subs, \"Length of indices list does not equal number of subjects, something went wrong\"\n",
    "\n",
    "    np.random.shuffle(indices) # shuffles in place\n",
    "\n",
    "    return np.array(indices)\n",
    "\n",
    "def split_train_test(subj_list, indices, test_fold):\n",
    "    \"\"\"\n",
    "    For a subj list, k-fold indices, and given fold, returns lists of train_subs and test_subs\n",
    "    \"\"\"\n",
    "\n",
    "    train_inds = np.where(indices!=test_fold)\n",
    "    test_inds = np.where(indices==test_fold)\n",
    "\n",
    "    train_subs = []\n",
    "    for sub in subj_list[train_inds]:\n",
    "        train_subs.append(sub)\n",
    "\n",
    "    test_subs = []\n",
    "    for sub in subj_list[test_inds]:\n",
    "        test_subs.append(sub)\n",
    "\n",
    "    return (train_subs, test_subs)\n",
    "\n",
    "\n",
    "\n",
    "def get_train_test_data(all_fc_data, train_subs, test_subs, behav_data, behav):\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts requested FC and behavioral data for a list of train_subs and test_subs\n",
    "    \"\"\"\n",
    "\n",
    "    train_vcts = all_fc_data.loc[train_subs, :]\n",
    "    test_vcts = all_fc_data.loc[test_subs, :]\n",
    "\n",
    "    train_behav = behav_data.loc[train_subs, behav]\n",
    "\n",
    "    return (train_vcts, train_behav, test_vcts)\n",
    "\n",
    "\n",
    "def select_features(train_vcts, train_behav, r_thresh=0.2, corr_type='pearson', verbose=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Runs the CPM feature selection step: \n",
    "    - correlates each edge with behavior, and returns a mask of edges that are correlated above some threshold, one for each tail (positive and negative)\n",
    "    \"\"\"\n",
    "\n",
    "    assert train_vcts.index.equals(train_behav.index), \"Row indices of FC vcts and behavior don't match!\"\n",
    "\n",
    "    # Correlate all edges with behav vector\n",
    "    if corr_type =='pearson':\n",
    "        cov = np.dot(train_behav.T - train_behav.mean(), train_vcts - train_vcts.mean(axis=0)) / (train_behav.shape[0]-1)\n",
    "        corr = cov / np.sqrt(np.var(train_behav, ddof=1) * np.var(train_vcts, axis=0, ddof=1))\n",
    "    elif corr_type =='spearman':\n",
    "        corr = []\n",
    "        for edge in train_vcts.columns:\n",
    "            r_val = sp.stats.spearmanr(train_vcts.loc[:,edge], train_behav)[0]\n",
    "            corr.append(r_val)\n",
    "\n",
    "    # Define positive and negative masks\n",
    "    mask_dict = {}\n",
    "    mask_dict[\"pos\"] = corr > r_thresh\n",
    "    mask_dict[\"neg\"] = corr < -r_thresh\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Found ({}/{}) edges positively/negatively correlated with behavior in the training set\".format(mask_dict[\"pos\"].sum(), mask_dict[\"neg\"].sum())) # for debugging\n",
    "\n",
    "    return mask_dict\n",
    "\n",
    "\n",
    "def build_model(train_vcts, mask_dict, train_behav):\n",
    "    \"\"\"\n",
    "    Builds a CPM model:\n",
    "    - takes a feature mask, sums all edges in the mask for each subject, and uses simple linear regression to relate summed network strength to behavior\n",
    "    \"\"\"\n",
    "\n",
    "    assert train_vcts.index.equals(train_behav.index), \"[ERROR FOUND] Row indices of FC vcts and behavior don't match!\"\n",
    "\n",
    "    model_dict = {}\n",
    "\n",
    "    # Loop through pos and neg tails\n",
    "    X_glm = np.zeros((train_vcts.shape[0], len(mask_dict.items())))\n",
    "\n",
    "    t = 0\n",
    "    for tail, mask in mask_dict.items():\n",
    "        X = train_vcts.values[:, mask].sum(axis=1)\n",
    "        X_glm[:, t] = X\n",
    "        y = train_behav\n",
    "        \n",
    "        (slope, intercept) = np.polyfit(X, y, 1)\n",
    "        model_dict[tail] = (slope, intercept)\n",
    "        t+=1\n",
    "\n",
    "    X_glm = np.c_[X_glm, np.ones(X_glm.shape[0])]\n",
    "    model_dict[\"glm\"] = tuple(np.linalg.lstsq(X_glm, y, rcond=None)[0])\n",
    "\n",
    "    return model_dict\n",
    "\n",
    "\n",
    "\n",
    "def apply_model(test_vcts, mask_dict, model_dict):\n",
    "    \"\"\"\n",
    "    Applies a previously trained linear regression model to a test set to generate predictions of behavior.\n",
    "    \"\"\"\n",
    "\n",
    "    behav_pred = {}\n",
    "\n",
    "    X_glm = np.zeros((test_vcts.shape[0], len(mask_dict.items())))\n",
    "\n",
    "    # Loop through pos and neg tails\n",
    "    t = 0\n",
    "    for tail, mask in mask_dict.items():\n",
    "      #print(tail, mask)\n",
    "      X = test_vcts.loc[:, mask].sum(axis=1)\n",
    "      X_glm[:, t] = X\n",
    "\n",
    "      slope, intercept = model_dict[tail]\n",
    "      behav_pred[tail] = slope*X + intercept\n",
    "      t+=1\n",
    "\n",
    "    X_glm = np.c_[X_glm, np.ones(X_glm.shape[0])]\n",
    "    behav_pred[\"glm\"] = np.dot(X_glm, model_dict[\"glm\"])\n",
    "\n",
    "    return behav_pred\n",
    "\n",
    "def cpm_wrapper(all_fc_data, all_behav_data,condition, behav,  k, **cpm_kwargs):\n",
    "\n",
    "    assert all_fc_data.index.equals(all_behav_data.index), \"Row (subject) indices of FC vcts and behavior don't match!\"\n",
    "\n",
    "    subj_list = all_fc_data.index # get subj_list from df index\n",
    "    \n",
    "    indices = mk_kfold_indices(subj_list, k)\n",
    "    \n",
    "    # Initialize df for storing observed and predicted behavior\n",
    "    col_list = []\n",
    "    for tail in [\"pos\", \"neg\", \"glm\"]:\n",
    "        col_list.append(behav + \" predicted (\" + tail + \")\")\n",
    "    col_list.append(behav + \" observed\")\n",
    "    behav_obs_pred = pd.DataFrame(index=subj_list, columns = col_list)\n",
    "    \n",
    "    # Initialize array for storing feature masks\n",
    "    n_edges = all_fc_data.shape[1]\n",
    "    all_masks = {}\n",
    "    all_masks[\"pos\"] = np.zeros((k, n_edges))\n",
    "    all_masks[\"neg\"] = np.zeros((k, n_edges))\n",
    "    \n",
    "    for fold in range(k):\n",
    "        #print(\"[INFO] doing fold {}\".format(fold))\n",
    "        train_subs, test_subs = split_train_test(subj_list, indices, test_fold=fold)\n",
    "        train_vcts, train_behav, test_vcts = get_train_test_data(all_fc_data, train_subs, test_subs, all_behav_data, behav=behav)\n",
    "        mask_dict = select_features(train_vcts, train_behav, **cpm_kwargs)\n",
    "        all_masks[\"pos\"][fold,:] = mask_dict[\"pos\"]\n",
    "        all_masks[\"neg\"][fold,:] = mask_dict[\"neg\"]\n",
    "        try:\n",
    "          model_dict = build_model(train_vcts, mask_dict, train_behav)\n",
    "          #print(model_dict.keys())\n",
    "          #print(\"[INFO] model building complete.\")\n",
    "        except Exception as e:\n",
    "          print(\"[ERROR FOUND] {} \\n\".format(e))\n",
    "        try:\n",
    "          behav_pred = apply_model(test_vcts, mask_dict, model_dict)\n",
    "          #print(\"[INFO] glm applied, behavior predicted with test set.\")\n",
    "        except Exception as e:\n",
    "          print(\"[ERROR FOUND] {} \\n\".format(e))\n",
    "        for tail, predictions in behav_pred.items():\n",
    "            behav_obs_pred.loc[test_subs, behav + \" predicted (\" + tail + \")\"] = predictions\n",
    "            \n",
    "    behav_obs_pred.loc[subj_list, behav + \" observed\"] = all_behav_data[behav]\n",
    "    \n",
    "    if not behav_obs_pred.empty: print('[INFO] CPM completed with %s folds.'%(k))\n",
    "    return behav_obs_pred, all_masks\n",
    "\n",
    "\n",
    "def plot_predictions(behav_obs_pred,color, tail=\"glm\"):\n",
    "    x = behav_obs_pred.filter(regex=(\"obs\")).astype(float)\n",
    "    y = behav_obs_pred.filter(regex=(tail)).astype(float)\n",
    "\n",
    "    g = sns.regplot(x=x.T.squeeze(), y=y.T.squeeze(), color=color)\n",
    "    ax_min = min(min(g.get_xlim()), min(g.get_ylim()))\n",
    "    ax_max = max(max(g.get_xlim()), max(g.get_ylim()))\n",
    "    g.set_xlim(ax_min, ax_max)\n",
    "    g.set_ylim(ax_min, ax_max)\n",
    "    g.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    #print(y.columns.values)\n",
    "    r = sp.stats.pearsonr(x['BMI observed'],y['BMI predicted (glm)'])\n",
    "    r_value = r[0]\n",
    "    p_value = r[1]\n",
    "    g.annotate('r = {0:.2f}'.format(r_value), xy = (0.7, 0.9), xycoords = 'axes fraction')\n",
    "    \n",
    "    return g\n",
    "\n",
    "\n",
    "def plot_consistent_edges(all_masks, roi_coords, tail, thresh = 1., color='gray'):\n",
    "    \n",
    "    edge_frac = (all_masks[tail].sum(axis=0))/(all_masks[tail].shape[0])\n",
    "    edge_frac_square = sp.spatial.distance.squareform(edge_frac)\n",
    "\n",
    "    node_mask = np.amax(edge_frac_square, axis=0) >= thresh # find nodes that have at least one edge that passes the threshold\n",
    "    node_size = edge_frac_square.sum(axis=0)*node_mask*20 # size nodes based on how many suprathreshold edges they have\n",
    "\n",
    "    plot_connectome(adjacency_matrix=edge_frac_square, edge_threshold=thresh,\n",
    "                    node_color = color,title=tail, node_coords=roi_coords, node_size=node_size,\n",
    "                    display_mode= 'lzry',\n",
    "                    edge_kwargs={\"linewidth\": 1, 'color': color})\n",
    "    print(\"For the {} tail, {} edges were selected in at least {}% of folds\".format(tail, (edge_frac>=thresh).sum(), thresh*100))\n",
    "\n",
    "    \n",
    "def cpmPipeline(cmap,condition, behav, matrices_path, cpm_kwargs, behavioral,cond_color,k):\n",
    "  # first step compute timeseries matrix\n",
    "  timeseries_matrices=glob.glob(os.path.join(matrices_path, \"sub*.txt\"))\n",
    "  # make functional connectivity matrix of individual subjects\n",
    "  fc_corr_dict,subj_list=makeFCM(cmap, timeseries_matrices, file_suffix=condition, functionals=None)\n",
    "  # put all subj functional connectivity matrix into a group fc matrix\n",
    "  all_fc_data = read_in_matrices(behavioral.index.values.tolist(), fc_corr_dict,file_suffix=condition)\n",
    "  # replace infinite values with nan\n",
    "  all_fc_data.replace([np.inf, -np.inf], np.nan)\n",
    "  # fill nan values with column average\n",
    "  all_fc_data.fillna(all_fc_data.mean(axis=1), inplace=True)\n",
    "\n",
    "  behav_obs_pred, all_masks = cpm_wrapper(all_fc_data, behavioral, condition, behav,k, **cpm_kwargs)\n",
    "\n",
    "  print(\"\\n\")\n",
    "  ICD.display(behav_obs_pred.head())\n",
    "  # plot scatter plot\n",
    "  print('\\nPlot of Observed vs. Predicted Behavior \\n')\n",
    "  g = plot_predictions(behav_obs_pred,cond_color)\n",
    "  g.set_title(condition.upper())\n",
    "  plt.show()\n",
    "\n",
    "  print(\"\\n\\n\\n\")\n",
    "\n",
    "  roi_coords=pd.read_csv('betaseries_rois.txt', sep='\\t')\n",
    "  roi_coords.set_index(\"Region\", inplace=True)\n",
    "  #ICD.display(roi_coords.head())\n",
    "  plot_consistent_edges(all_masks, roi_coords, \"pos\", thresh = 0.8, color = 'deeppink')\n",
    "  plot_consistent_edges(all_masks, roi_coords, \"neg\", thresh = 0.8, color = 'purple')\n",
    "\n",
    "def main(condition, behav, cond_color,matrices_path,cmap, k):\n",
    "  #setup input parameters \n",
    "  matrices_path='/content'\n",
    "  cpm_kwargs = {'r_thresh': 0.2, 'corr_type': 'pearson'} # these are the defaults, but it's still good to be explicit\n",
    "\n",
    "  #run pipeline\n",
    "  cpmPipeline(cmap,condition, behav, matrices_path, cpm_kwargs, behavioral, cond_color,k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input needed:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* set of functional connectivity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subj_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ea392ef2eee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# get subject id list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msubject_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msubject_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'subj_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# need to get subject ids from available functional connectivity matrices (fcm) \n",
    "path='/projects/niblab/experiments/chocolate_milkshake/data/betaseries/by_sub'\n",
    "files=glob.glob(os.path.join(path,\"*.txt\"))\n",
    "# get subject id list\n",
    "subject_ids=[x.split(\"/\")[-1].split(\"_\")[0] for x in files]\n",
    "subject_ids=list(set(subj_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Scan Date</th>\n",
       "      <th>Scan time</th>\n",
       "      <th>Ate (hrs)</th>\n",
       "      <th>Hunger</th>\n",
       "      <th>Snack</th>\n",
       "      <th>Sex (1=m, 2=f)</th>\n",
       "      <th>Protocol #</th>\n",
       "      <th>Paradigm 1</th>\n",
       "      <th>Paradigm 2</th>\n",
       "      <th>Paradigm 3</th>\n",
       "      <th>Paradigm 4</th>\n",
       "      <th>Paradigm 5</th>\n",
       "      <th>Paradigm 6</th>\n",
       "      <th>Paradigm 7</th>\n",
       "      <th>Notes:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8/4/2012</td>\n",
       "      <td>12:03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>imagine</td>\n",
       "      <td>milkB</td>\n",
       "      <td>milkC</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6/29/2012</td>\n",
       "      <td>13:30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkA</td>\n",
       "      <td>milkB</td>\n",
       "      <td>rage</td>\n",
       "      <td>imagine</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30-Jul</td>\n",
       "      <td>15:13</td>\n",
       "      <td>999.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkA</td>\n",
       "      <td>milkB</td>\n",
       "      <td>imagine</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8/5/2012</td>\n",
       "      <td>10:05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkC</td>\n",
       "      <td>milkB</td>\n",
       "      <td>imagine</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Scan Date Scan time  Ate (hrs)  Hunger  Snack  Sex (1=m, 2=f)  \\\n",
       "0   1   8/4/2012     12:03        2.0     6.0    0.0             1.0   \n",
       "1   2  6/29/2012     13:30        4.0     4.0    0.0             1.0   \n",
       "2   3        NaN       NaN        NaN     NaN    NaN             NaN   \n",
       "3   4     30-Jul     15:13      999.0     7.0    0.0             2.0   \n",
       "4   5   8/5/2012     10:05        8.0     7.0    0.0             1.0   \n",
       "\n",
       "   Protocol #       Paradigm 1 Paradigm 2 Paradigm 3 Paradigm 4 Paradigm 5  \\\n",
       "0         3.0  local field map    imagine      milkB      milkC       GNG1   \n",
       "1       999.0  local field map      milkA      milkB       rage    imagine   \n",
       "2         NaN              NaN        NaN        NaN        NaN        NaN   \n",
       "3         1.0  local field map      milkA      milkB    imagine       GNG1   \n",
       "4         4.0  local field map      milkC      milkB    imagine       GNG2   \n",
       "\n",
       "  Paradigm 6 Paradigm 7 Notes:  \n",
       "0       GNG2       rage    NaN  \n",
       "1       GNG1       GNG2    NaN  \n",
       "2        NaN        NaN    NaN  \n",
       "3       GNG2       rage    NaN  \n",
       "4       GNG1       rage    NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load behavioral data\n",
    "behavioral_file='/projects/niblab/experiments/chocolate_milkshake/data/behavioral_wave1.csv'\n",
    "df_behavioral=pd.read_csv(behavioral_file)\n",
    "df_behavioral.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Scan Date</th>\n",
       "      <th>Scan time</th>\n",
       "      <th>Ate (hrs)</th>\n",
       "      <th>Hunger</th>\n",
       "      <th>Snack</th>\n",
       "      <th>Sex (1=m, 2=f)</th>\n",
       "      <th>Protocol #</th>\n",
       "      <th>Paradigm 1</th>\n",
       "      <th>Paradigm 2</th>\n",
       "      <th>Paradigm 3</th>\n",
       "      <th>Paradigm 4</th>\n",
       "      <th>Paradigm 5</th>\n",
       "      <th>Paradigm 6</th>\n",
       "      <th>Paradigm 7</th>\n",
       "      <th>Notes:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-001</td>\n",
       "      <td>8/4/2012</td>\n",
       "      <td>12:03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>imagine</td>\n",
       "      <td>milkB</td>\n",
       "      <td>milkC</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>6/29/2012</td>\n",
       "      <td>13:30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkA</td>\n",
       "      <td>milkB</td>\n",
       "      <td>rage</td>\n",
       "      <td>imagine</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-004</td>\n",
       "      <td>30-Jul</td>\n",
       "      <td>15:13</td>\n",
       "      <td>999.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkA</td>\n",
       "      <td>milkB</td>\n",
       "      <td>imagine</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-005</td>\n",
       "      <td>8/5/2012</td>\n",
       "      <td>10:05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkC</td>\n",
       "      <td>milkB</td>\n",
       "      <td>imagine</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Scan Date Scan time  Ate (hrs)  Hunger  Snack  Sex (1=m, 2=f)  \\\n",
       "0  sub-001   8/4/2012     12:03        2.0     6.0    0.0             1.0   \n",
       "1  sub-002  6/29/2012     13:30        4.0     4.0    0.0             1.0   \n",
       "2  sub-003        NaN       NaN        NaN     NaN    NaN             NaN   \n",
       "3  sub-004     30-Jul     15:13      999.0     7.0    0.0             2.0   \n",
       "4  sub-005   8/5/2012     10:05        8.0     7.0    0.0             1.0   \n",
       "\n",
       "   Protocol #       Paradigm 1 Paradigm 2 Paradigm 3 Paradigm 4 Paradigm 5  \\\n",
       "0         3.0  local field map    imagine      milkB      milkC       GNG1   \n",
       "1       999.0  local field map      milkA      milkB       rage    imagine   \n",
       "2         NaN              NaN        NaN        NaN        NaN        NaN   \n",
       "3         1.0  local field map      milkA      milkB    imagine       GNG1   \n",
       "4         4.0  local field map      milkC      milkB    imagine       GNG2   \n",
       "\n",
       "  Paradigm 6 Paradigm 7 Notes:  \n",
       "0       GNG2       rage    NaN  \n",
       "1       GNG1       GNG2    NaN  \n",
       "2        NaN        NaN    NaN  \n",
       "3       GNG2       rage    NaN  \n",
       "4       GNG1       rage    NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reformat id in index\n",
    "for id_num in df_behavioral['ID']:\n",
    "    new_value='sub-%03d'%id_num\n",
    "    #print(new_value)\n",
    "    #print(new_value,df_behavioral.iloc[id_num-1, df_behavioral.columns.get_loc('ID')])\n",
    "    df_behavioral.iloc[id_num-1, df_behavioral.columns.get_loc('ID')]=new_value\n",
    "    \n",
    "    \n",
    "# drop subject rows that don't have matrices available\n",
    "df_behavioral.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scan Date</th>\n",
       "      <th>Scan time</th>\n",
       "      <th>Ate (hrs)</th>\n",
       "      <th>Hunger</th>\n",
       "      <th>Snack</th>\n",
       "      <th>Sex (1=m, 2=f)</th>\n",
       "      <th>Protocol #</th>\n",
       "      <th>Paradigm 1</th>\n",
       "      <th>Paradigm 2</th>\n",
       "      <th>Paradigm 3</th>\n",
       "      <th>Paradigm 4</th>\n",
       "      <th>Paradigm 5</th>\n",
       "      <th>Paradigm 6</th>\n",
       "      <th>Paradigm 7</th>\n",
       "      <th>Notes:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-001</th>\n",
       "      <td>8/4/2012</td>\n",
       "      <td>12:03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>imagine</td>\n",
       "      <td>milkB</td>\n",
       "      <td>milkC</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-002</th>\n",
       "      <td>6/29/2012</td>\n",
       "      <td>13:30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkA</td>\n",
       "      <td>milkB</td>\n",
       "      <td>rage</td>\n",
       "      <td>imagine</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-004</th>\n",
       "      <td>30-Jul</td>\n",
       "      <td>15:13</td>\n",
       "      <td>999.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkA</td>\n",
       "      <td>milkB</td>\n",
       "      <td>imagine</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-005</th>\n",
       "      <td>8/5/2012</td>\n",
       "      <td>10:05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkC</td>\n",
       "      <td>milkB</td>\n",
       "      <td>imagine</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Scan Date Scan time  Ate (hrs)  Hunger  Snack  Sex (1=m, 2=f)  \\\n",
       "Subject                                                                  \n",
       "sub-001   8/4/2012     12:03        2.0     6.0    0.0             1.0   \n",
       "sub-002  6/29/2012     13:30        4.0     4.0    0.0             1.0   \n",
       "sub-003        NaN       NaN        NaN     NaN    NaN             NaN   \n",
       "sub-004     30-Jul     15:13      999.0     7.0    0.0             2.0   \n",
       "sub-005   8/5/2012     10:05        8.0     7.0    0.0             1.0   \n",
       "\n",
       "         Protocol #       Paradigm 1 Paradigm 2 Paradigm 3 Paradigm 4  \\\n",
       "Subject                                                                 \n",
       "sub-001         3.0  local field map    imagine      milkB      milkC   \n",
       "sub-002       999.0  local field map      milkA      milkB       rage   \n",
       "sub-003         NaN              NaN        NaN        NaN        NaN   \n",
       "sub-004         1.0  local field map      milkA      milkB    imagine   \n",
       "sub-005         4.0  local field map      milkC      milkB    imagine   \n",
       "\n",
       "        Paradigm 5 Paradigm 6 Paradigm 7 Notes:  \n",
       "Subject                                          \n",
       "sub-001       GNG1       GNG2       rage    NaN  \n",
       "sub-002    imagine       GNG1       GNG2    NaN  \n",
       "sub-003        NaN        NaN        NaN    NaN  \n",
       "sub-004       GNG1       GNG2       rage    NaN  \n",
       "sub-005       GNG2       GNG1       rage    NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set index to the ID column and rename it\n",
    "df_behavioral.set_index(\"ID\", inplace=True)\n",
    "df_behavioral.index.name=\"Subject\"\n",
    "df_behavioral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop subjects without fcms\n",
    "bad_subjects=[x for x in df_behavioral.index.values if x not in subject_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavioral file subject count:  154\n",
      "FCM id count:  115\n",
      "Subjects count dropping:  39\n"
     ]
    }
   ],
   "source": [
    "print(\"Behavioral file subject count: \", len(df_behavioral.index.values))\n",
    "print(\"FCM id count: \", len(subject_ids))\n",
    "print(\"Subjects count dropping: \", len(bad_subjects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scan Date</th>\n",
       "      <th>Scan time</th>\n",
       "      <th>Ate (hrs)</th>\n",
       "      <th>Hunger</th>\n",
       "      <th>Snack</th>\n",
       "      <th>Sex (1=m, 2=f)</th>\n",
       "      <th>Protocol #</th>\n",
       "      <th>Paradigm 1</th>\n",
       "      <th>Paradigm 2</th>\n",
       "      <th>Paradigm 3</th>\n",
       "      <th>Paradigm 4</th>\n",
       "      <th>Paradigm 5</th>\n",
       "      <th>Paradigm 6</th>\n",
       "      <th>Paradigm 7</th>\n",
       "      <th>Notes:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-001</th>\n",
       "      <td>8/4/2012</td>\n",
       "      <td>12:03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>imagine</td>\n",
       "      <td>milkB</td>\n",
       "      <td>milkC</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-004</th>\n",
       "      <td>30-Jul</td>\n",
       "      <td>15:13</td>\n",
       "      <td>999.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkA</td>\n",
       "      <td>milkB</td>\n",
       "      <td>imagine</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-005</th>\n",
       "      <td>8/5/2012</td>\n",
       "      <td>10:05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkC</td>\n",
       "      <td>milkB</td>\n",
       "      <td>imagine</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-009</th>\n",
       "      <td>8/5/2012</td>\n",
       "      <td>12:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>milkB</td>\n",
       "      <td>milkD</td>\n",
       "      <td>imagine</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-011</th>\n",
       "      <td>8/1/2012</td>\n",
       "      <td>12:28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>local field map</td>\n",
       "      <td>milkB</td>\n",
       "      <td>milkA</td>\n",
       "      <td>GNG2</td>\n",
       "      <td>GNG1</td>\n",
       "      <td>imagine</td>\n",
       "      <td>rage</td>\n",
       "      <td>participant moved legs in between scans, but s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Scan Date Scan time  Ate (hrs)  Hunger  Snack  Sex (1=m, 2=f)  \\\n",
       "Subject                                                                 \n",
       "sub-001  8/4/2012     12:03        2.0     6.0    0.0             1.0   \n",
       "sub-004    30-Jul     15:13      999.0     7.0    0.0             2.0   \n",
       "sub-005  8/5/2012     10:05        8.0     7.0    0.0             1.0   \n",
       "sub-009  8/5/2012     12:00       12.0     4.0    0.0             1.0   \n",
       "sub-011  8/1/2012     12:28       14.0     5.0    0.0             2.0   \n",
       "\n",
       "         Protocol #       Paradigm 1 Paradigm 2 Paradigm 3 Paradigm 4  \\\n",
       "Subject                                                                 \n",
       "sub-001         3.0  local field map    imagine      milkB      milkC   \n",
       "sub-004         1.0  local field map      milkA      milkB    imagine   \n",
       "sub-005         4.0  local field map      milkC      milkB    imagine   \n",
       "sub-009         5.0  local field map       GNG1       GNG2      milkB   \n",
       "sub-011         2.0  local field map      milkB      milkA       GNG2   \n",
       "\n",
       "        Paradigm 5 Paradigm 6 Paradigm 7  \\\n",
       "Subject                                    \n",
       "sub-001       GNG1       GNG2       rage   \n",
       "sub-004       GNG1       GNG2       rage   \n",
       "sub-005       GNG2       GNG1       rage   \n",
       "sub-009      milkD    imagine       rage   \n",
       "sub-011       GNG1    imagine       rage   \n",
       "\n",
       "                                                    Notes:  \n",
       "Subject                                                     \n",
       "sub-001                                                NaN  \n",
       "sub-004                                                NaN  \n",
       "sub-005                                                NaN  \n",
       "sub-009                                                NaN  \n",
       "sub-011  participant moved legs in between scans, but s...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_behavioral.drop(bad_subjects,axis=0,inplace=True)\n",
    "df_behavioral.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Behavioral Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hunger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav = 'Hunger'\n",
    "#sns.distplot(df_behavioral[behav], color=\"purple\",kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"})\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/niblab/experiments/chocolate_milkshake/data/code\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
