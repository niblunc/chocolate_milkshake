{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chocolate Milkshake Betaseries \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Conents:\n",
    "\n",
    "* [Load and set variables](#first-bullet)\n",
    "* [FSL feat1 analysis](#second-bullet)  \n",
    "* [Concatenate with fslmerge](#third-bullet)\n",
    "* [Transform functionals with flirt and fslmath](#fourth-bullet)\n",
    "* [Pull individual ROI timeseries by subject](#fifth-bullet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Paradigm**\n",
    "\n",
    "Functional Tasks: \n",
    "\n",
    "    milkshake pic, milkshake receipt, h20 pic, h20 receipt, milkshake minus h20, milkshake plus h20, rinse\n",
    "\n",
    "Furthermore, `milkshake` is broken down into the following specifities:   \n",
    "      \n",
    "    HF(high fat, HS(high sugar), and respectively, LF(low fat), LS(low sugar)   \n",
    "\n",
    "with the following relationships:  \n",
    "    \n",
    "    HF_HS, HF_LS, LF_HS, LF_LS\n",
    "\n",
    "\n",
    "Example set of onsets for a subject:  \n",
    "\n",
    "\n",
    "`\n",
    "$ /pwd ~/preprocessed/sub-001/ses-1/func/onsets\n",
    "mkB_h20_pic.ev          mkB_HS_plus_h20.ev      mkB_rinse.ev            mkC_HF_LS_receipt.ev    mkC_milkshake_pic.ev\n",
    "mkB_h20_receipt.ev      mkB_LF_HS_minus_h20.ev  mkC_h20_pic.ev          mkC_HS_plus_h20.ev      mkC_rinse.ev\n",
    "mkB_HF_HS_minus_h20.ev  mkB_LF_HS_receipt.ev    mkC_h20_receipt.ev      mkC_LF_HS_minus_h20.ev\n",
    "mkB_HF_HS_receipt.ev    mkB_LF_LS_receipt.ev    mkC_HF_HS_minus_h20.ev  mkC_LF_HS_receipt.ev\n",
    "mkB_HF_LS_receipt.ev    mkB_milkshake_pic.ev    mkC_HF_HS_receipt.ev    mkC_LF_LS_receipt.ev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import subprocess\n",
    "import re\n",
    "from IPython.core import display as ICD\n",
    "from os import listdir\n",
    "from shutil import rmtree\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and set variables <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and set variables\n",
    "beta_path='/projects/niblab/experiments/chocolate_milkshake/data/betaseries'\n",
    "concat_path=\"/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat\"\n",
    "subject_folders=sorted(glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/bids/derivatives/preprocessed/sub-*'))\n",
    "\n",
    "data_dict={}\n",
    "bad_subs=[]\n",
    "\n",
    "for folder in subject_folders:\n",
    "    subject_id=folder.split(\"/\")[-1]\n",
    "    #print(os.path.join(folder,'ses-1/analysis/beta/*.feat'))\n",
    "    tasks=glob.glob(os.path.join(folder,'ses-1/analysis/beta/*'))\n",
    "    #print(tasks)\n",
    "    if not tasks:\n",
    "        bad_subs.append(subject_id)\n",
    "    else:\n",
    "        if subject_id not in data_dict:\n",
    "            data_dict[subject_id]={}\n",
    "        for task_folder in tasks:\n",
    "            #print(task_folder)\n",
    "            task=task_folder.split(\"/\")[-1].split('.')[0]\n",
    "            #print(task)\n",
    "            if task not in data_dict[subject_id]:\n",
    "                data_dict[subject_id][task]={}\n",
    "            pes=glob.glob(os.path.join(task_folder, '*.feat'))\n",
    "            data_dict[subject_id][task]=pes\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSL feat1 analysis <a class='anchor' id='second-bullet'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] set of unique chocolate evs: \n",
      " {'HF_HS_minus_h20', 'HF_HS_receipt', 'LF_HS_minus_h20', 'h20_pic', 'HS_plus_h20', 'rinse', 'milkshake_pic', 'h20_receipt', 'HF_LS_receipt', 'LF_LS_receipt', 'LF_HS_receipt'}\n"
     ]
    }
   ],
   "source": [
    "choco_evs=glob.glob('/projects/niblab/data/eric_data/ev_files/milkshake/*.ev')\n",
    "choco_evs=[x.split('/')[-1].replace('.ev',\"\") for x in choco_evs]\n",
    "choco_evs=[re.sub('mk[A-Z]_', '',x) for x in choco_evs]\n",
    "choco_evs=set(choco_evs)\n",
    "print(\"[INFO] set of unique chocolate evs: \\n\", choco_evs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNG  GNG_wrong\timagine  milkshake\r\n"
     ]
    }
   ],
   "source": [
    "# get the unique tasks\n",
    "!ls /projects/niblab/data/eric_data/ev_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make subject condition feat files (`.fsf`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file(sub_id, ses_id, trial_id, output_dir, task,data_dict):\n",
    "    with open(os.path.join('/projects/niblab/experiments/chocolate_milkshake/data/code/beta_design.fsf'),'r') as infile:\n",
    "        tempfsf=infile.read()\n",
    "        #\n",
    "        if not os.path.exists(os.path.join(output_dir, \"design_files\")):\n",
    "            os.makedirs(os.path.join(output_dir, \"design_files\"))\n",
    "        #print(output_dir)\n",
    "        design_fileout = os.path.join(output_dir, \"design_files/%s_%s_%s_feat1.fsf\"%(sub_id, ses_id, trial_id))\n",
    "        out_param = data_dict[sub_id][task][\"TRIALS\"][\"TRIAL%s\"%trial_id][\"OUTPUT\"]\n",
    "        func_param = data_dict[sub_id][task][\"FUNCRUN\"]\n",
    "        confound_param = data_dict[sub_id][task][\"CONFOUND\"]\n",
    "        trial_param = data_dict[sub_id][task][\"TRIALS\"][\"TRIAL%s\"%trial_id][\"TRIAL\"]\n",
    "        nuis_param = data_dict[sub_id][task][\"TRIALS\"][\"TRIAL%s\"%trial_id][\"NUIS\"]\n",
    "\n",
    "        tempfsf = tempfsf.replace(\"OUTPUT\", out_param)\n",
    "        tempfsf = tempfsf.replace(\"FUNCRUN\", func_param) \n",
    "        tempfsf = tempfsf.replace(\"CONFOUND\", confound_param)\n",
    "        tempfsf = tempfsf.replace(\"TRIAL\", trial_param)\n",
    "        tempfsf = tempfsf.replace(\"NUIS\", nuis_param)\n",
    "\n",
    "        for i in range(6):\n",
    "            moco = data_dict[sub_id][task][\"MOCO%i\"%i]\n",
    "            tempfsf = tempfsf.replace(\"MOCO%i\"%i, moco)\n",
    "        try:\n",
    "            with open(design_fileout,'w') as outfile:\n",
    "                outfile.write(tempfsf)\n",
    "            outfile.close()\n",
    "        except:\n",
    "            print(\"BAD SUBJECT \", sub_id)\n",
    "        infile.close()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate (fslmerge) data <a class='anchor' id='third-bullet'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Concatenated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat/sub-001_task-milkshakeB.nii.gz',\n",
       " '/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat/sub-001_task-milkshakeC.nii.gz',\n",
       " '/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat/sub-004_task-milkshakeA.nii.gz',\n",
       " '/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat/sub-004_task-milkshakeB.nii.gz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab concatenated (fslmerge) data\n",
    "\n",
    "fslmerged_files=glob.glob(os.path.join(concat_path,'*.nii.gz'))\n",
    "fslmerged_files[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill dictionary with concatenated files\n",
    "for nifti in fslmerged_files:\n",
    "    task=nifti.split(\"/\")[-1].split(\"_\")[1].split('.')[0]\n",
    "    subject_id=nifti.split(\"/\")[-1].split(\"_\")[0]\n",
    "    key=nifti.split(\"/\")[-1].split(\".\")[0].split('_')[1]\n",
    "    key=key+\"_concat\"\n",
    "    #print(subject_id)\n",
    "    #data_dict[subject_id][task]['concat']=nifti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Functionals (flirt & fslmaths) <a class='anchor' id='fourth-bullet'></a> \n",
    "To use the BigBrain300 rois we need to transform the nifti task files to match the mask.\n",
    "ROIs location on renci: `/projects/niblab/parcellations/chocolate_decoding_rois`   \n",
    "\n",
    "Big Brain 300: `/projects/niblab/parcellations/chocolate_decoding_rois/old_rois/bigBrain300_atlas`\n",
    "  \n",
    "`flirt`: the main program that performs affine registration. The options we use here:  \n",
    "* `-in`, an input  \n",
    "* `-ref`, a reference volume  \n",
    "* `applyxfm`, `-init` and `-out`, apply a saved transformation to a volume   \n",
    "\n",
    "  \n",
    "  \n",
    "*For these usages the reference volume must still be specified as this sets the voxel and image dimensions of the resulting volume.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] transform afunctionals to match the mask.\n",
      "[INFO] transformation process complete.\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] transform afunctionals to match the mask.')\n",
    "\n",
    "reference_nifti='/projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.nii.gz'\n",
    "reference_mat='/projects/niblab/parcellations/chocolate_decoding_rois/mni2ace.mat'\n",
    "for nii in fslmerged_files:\n",
    "    \n",
    "    # setup and run flirt\n",
    "    nii=nii.replace('.nii.gz', '')\n",
    "    out=nii+'_3mm'\n",
    "    flirt_cmd=\"flirt -in {} -ref {} -init {} -applyxfm -out {}\".format(nii, reference_nifti, reference_mat, out)\n",
    "    #print('[INFO] flirt command: \\n{}'.format(flirt_cmd))\n",
    "    #os.system(flirt_cmd)\n",
    "    \n",
    "    fslmaths_cmd='fslmaths {} -thr 0.9 {}'.format(out,out)\n",
    "    #print('[INFO] fslmaths command: \\n{}'.format(fslmaths_cmd))\n",
    "    #os.system(fslmaths_cmd)\n",
    "    \n",
    "print('[INFO] transformation process complete.')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull ROI timeseries  <a class='anchor' id='fifth-bullet'></a>\n",
    "\n",
    "Pull individual rois timeseries for each subject. \n",
    "\n",
    "Example command:  \n",
    "\n",
    "\n",
    "    fslmeants -i ~/sub-001_punish.nii.gz -o ~/3_pull_timeseries/sub-001_punish_AI_35_23_-6_asymPREPspace.nii.gz.txt -m ~/AI_35_23_-6_asymPREPspace.nii.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunks(l,n):\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "\n",
    "def pull_timeseries(roi_list, bb300_path='/projects/niblab/parcellations/bigbrain300',roi_df='/projects/niblab/parcellations/bigbrain300/renaming.csv'):\n",
    "\n",
    "    \n",
    "    bad_subs=[]\n",
    "    #ICD.display(roi_df)\n",
    "\n",
    "    # load asymmetrical nifti roi files\n",
    "    asym_niftis=glob.glob(\"/projects/niblab/parcellations/bigbrain300/MNI152Asymmetrical_3mm/*.nii.gz\")\n",
    "\n",
    "    # load roi list\n",
    "    out_dir = os.path.join(beta_path, 'rois/big300')\n",
    "    #print('[INFO] OUT DIRECTORY: %s \\n'%out_dir)\n",
    "\n",
    "    #roi_df.set_index(\"final order name\", inplace=True)\n",
    "    #ICD.display(roi_df)#.head())\n",
    "\n",
    "    # run parallel job pools\n",
    "\n",
    "\n",
    "    # loop through the roi file list\n",
    "    #print(roi_list[:3])\n",
    "    for nifti in sorted(roi_list):\n",
    "        #print('[INFO] loop1')\n",
    "        subj_id = nifti.split(\"/\")[-1].split(\"_\")[0]\n",
    "        subj_condition=nifti.split(\"/\")[-1].split(\"_\")[1].split(\".\")[0]\n",
    "        #print('[INFO] roi: %s %s'%(subj_id, subj_condition))\n",
    "\n",
    "        # loop through roi reference list\n",
    "        for ref_nifti in sorted(asym_niftis):\n",
    "            #print('[INFO] reference roi: %s'%ref_nifti)\n",
    "            roi = ref_nifti.split('/')[-1].split(\".\")[0]\n",
    "            out_path = os.path.join(out_dir, \"{}_{}_{}.txt\".format(subj_id, subj_condition, roi))\n",
    "            #print(roi, out_path)\n",
    "            cmd='fslmeants -i {} -o {} -m {}'.format(nifti, out_path, ref_nifti)\n",
    "            try:\n",
    "                cmd='fslmeants -i {} -o {} -m {}'.format(nifti, out_path, ref_nifti)\n",
    "                #print(\"Running shell command: {}\".format(cmd))\n",
    "                #os.system(cmd)\n",
    "            except:\n",
    "                bad_subs.append((subj_id, subj_condition))\n",
    "        \n",
    "        #print('[INFO] finished processing for %s'%subj_id)\n",
    "\n",
    "\n",
    "    return \"%s\"%bad_subs\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading roi and reference file....\n",
      "[INFO] 224 task roi nifti files being processed.\n",
      "[INFO] chunksize: 10\n",
      "[INFO] process complete.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "# load roi\n",
    "print(\"[INFO] loading roi and reference file....\")\n",
    "\n",
    "# task rois loaded\n",
    "task_rois=glob.glob(os.path.join(concat_path,'*_3mm.nii.gz'))\n",
    "#task_rois[:5]\n",
    "print(\"[INFO] {} task roi nifti files being processed.\".format(len(task_rois)))\n",
    "\n",
    "chunksize=10\n",
    "print(\"[INFO] chunksize: {}\".format(chunksize))\n",
    "chunk_list=chunks(task_rois, chunksize)\n",
    "#roi_df['network']\n",
    "# pull timeseries by rois --fslmeants command\n",
    "\n",
    "\n",
    "with Pool(5) as p:\n",
    "    p.map(pull_timeseries, chunk_list)\n",
    "print(\"[INFO] process complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submit process as a batch job for large datasets**  \n",
    "\n",
    "Two files:  \n",
    "- timeseries_pull.job  \n",
    "- timeseries_pull.py  \n",
    "\n",
    "*quick view of file contents below* -- note,for now paths may need to be updated directly in the scripts for your unqiue setup, flexible script in progress.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "#SBATCH --job-name=timeseriespull\r\n",
      "#SBATCH -o /projects/niblab/experiments/chocolate_milkshake/data/error_files/timepull_out_%A.txt\r\n",
      "#SBATCH -e /projects/niblab/experiments/chocolate_milkshake/data/error_files/timepull_beta_err_%A.txt\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "/projects/niblab/modules/software/miniconda3/miniconda3/bin/python3 /projects/niblab/experiments/chocolate_milkshake/data/code/timeseries_pull.py\r\n"
     ]
    }
   ],
   "source": [
    "!cat /projects/niblab/experiments/chocolate_milkshake/data/code/timeseries_pull.job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import glob\r\n",
      "import os\r\n",
      "import pandas as pd\r\n",
      "import argparse\r\n",
      "import subprocess\r\n",
      "import re\r\n",
      "\r\n",
      "from IPython.core import display as ICD\r\n",
      "from os import listdir\r\n",
      "from shutil import rmtree\r\n",
      "from subprocess import check_output\r\n",
      "\r\n",
      "\r\n",
      "subject_folders=sorted(glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/bids/derivatives/preprocessed/sub-*'))\r\n",
      "beta_path='/projects/niblab/experiments/chocolate_milkshake/data/betaseries'\r\n",
      "concat_path=\"/projects/niblab/experiments/chocolate_milkshake/data/betaseries/niftis_concat\"\r\n",
      "\r\n",
      "fslmerged_files=glob.glob(os.path.join(concat_path,'*.nii.gz'))\r\n",
      "fslmerged_files[:4]\r\n",
      "\r\n",
      "\r\n",
      "data_dict={}\r\n",
      "bad_subs=[]\r\n",
      "\r\n",
      "\r\n",
      "for folder in subject_folders:\r\n",
      "    subject_id=folder.split(\"/\")[-1]\r\n",
      "    #print(os.path.join(folder,'ses-1/analysis/beta/*.feat'))\r\n",
      "    tasks=glob.glob(os.path.join(folder,'ses-1/analysis/beta/*'))\r\n",
      "    #print(tasks)\r\n",
      "    if not tasks:\r\n",
      "        bad_subs.append(subject_id)\r\n",
      "    else:\r\n",
      "        if subject_id not in data_dict:\r\n",
      "            data_dict[subject_id]={}\r\n",
      "        for task_folder in tasks:\r\n",
      "            #print(task_folder)\r\n",
      "            task=task_folder.split(\"/\")[-1].split('.')[0]\r\n",
      "            #print(task)\r\n",
      "            if task not in data_dict[subject_id]:\r\n",
      "                data_dict[subject_id][task]={}\r\n",
      "            pes=glob.glob(os.path.join(task_folder, '*.feat'))\r\n",
      "            data_dict[subject_id][task]=pes\r\n",
      "\r\n",
      "      \r\n",
      "                \r\n",
      "\r\n",
      "\r\n",
      "for nifti in fslmerged_files:\r\n",
      "    task=nifti.split(\"/\")[-1].split(\"_\")[1].split('.')[0]\r\n",
      "    subject_id=nifti.split(\"/\")[-1].split(\"_\")[0]\r\n",
      "    key=nifti.split(\"/\")[-1].split(\".\")[0].split('_')[1]\r\n",
      "    key=key+\"_concat\"\r\n",
      "    #print(subject_id)\r\n",
      "    #data_dict[subject_id][task]['concat']=nifti\r\n",
      "\r\n",
      "def chunks(l,n):\r\n",
      "    return [l[i:i+n] for i in range(0, len(l), n)]\r\n",
      "\r\n",
      "\r\n",
      "def pull_timeseries(roi_list, bb300_path='/projects/niblab/parcellations/bigbrain300',roi_df='/projects/niblab/parcellations/bigbrain300/renaming.csv'):\r\n",
      "\r\n",
      "    \r\n",
      "    bad_subs=[]\r\n",
      "    #ICD.display(roi_df)\r\n",
      "\r\n",
      "    # load asymmetrical nifti roi files\r\n",
      "    asym_niftis=glob.glob(\"/projects/niblab/parcellations/bigbrain300/MNI152Asymmetrical_3mm/*.nii.gz\")\r\n",
      "\r\n",
      "    # load roi list\r\n",
      "    out_dir = os.path.join(beta_path, 'rois/big300')\r\n",
      "    #print('[INFO] OUT DIRECTORY: %s \\n'%out_dir)\r\n",
      "\r\n",
      "    #roi_df.set_index(\"final order name\", inplace=True)\r\n",
      "    #ICD.display(roi_df)#.head())\r\n",
      "\r\n",
      "    # run parallel job pools\r\n",
      "\r\n",
      "\r\n",
      "    # loop through the roi file list\r\n",
      "    #print(roi_list[:3])\r\n",
      "    for nifti in sorted(roi_list):\r\n",
      "        #print('[INFO] loop1')\r\n",
      "        subj_id = nifti.split(\"/\")[-1].split(\"_\")[0]\r\n",
      "        subj_condition=nifti.split(\"/\")[-1].split(\"_\")[1].split(\".\")[0]\r\n",
      "        #print('[INFO] roi: %s %s'%(subj_id, subj_condition))\r\n",
      "\r\n",
      "        # loop through roi reference list\r\n",
      "        for ref_nifti in sorted(asym_niftis):\r\n",
      "            #print('[INFO] reference roi: %s'%ref_nifti)\r\n",
      "            roi = ref_nifti.split('/')[-1].split(\".\")[0]\r\n",
      "            out_path = os.path.join(out_dir, \"{}_{}_{}.txt\".format(subj_id, subj_condition, roi))\r\n",
      "            #print(roi, out_path)\r\n",
      "            cmd='fslmeants -i {} -o {} -m {}'.format(nifti, out_path, ref_nifti)\r\n",
      "            try:\r\n",
      "                cmd='fslmeants -i {} -o {} -m {}'.format(nifti, out_path, ref_nifti)\r\n",
      "                #print(\"Running shell command: {}\".format(cmd))\r\n",
      "                os.system(cmd)\r\n",
      "            except:\r\n",
      "                bad_subs.append((subj_id, subj_condition))\r\n",
      "        \r\n",
      "        print('[INFO] finished processing for %s'%subj_id)\r\n",
      "\r\n",
      "\r\n",
      "    return \"%s\"%bad_subs\r\n",
      "\r\n",
      "   \r\n",
      "    \r\n",
      "from multiprocessing import Pool\r\n",
      "# load roi\r\n",
      "print(\"[INFO] loading roi and reference file....\")\r\n",
      "\r\n",
      "# task rois loaded\r\n",
      "task_rois=glob.glob(os.path.join(concat_path,'*_3mm.nii.gz'))\r\n",
      "#task_rois[:5]\r\n",
      "print(\"[INFO] {} task roi nifti files being processed.\".format(len(task_rois)))\r\n",
      "\r\n",
      "chunksize=15\r\n",
      "print(\"[INFO] chunksize: {}\".format(chunksize))\r\n",
      "chunk_list=chunks(task_rois, chunksize)\r\n",
      "#roi_df['network']\r\n",
      "# pull timeseries by rois --fslmeants command\r\n",
      "\r\n",
      "\r\n",
      "with Pool(15) as p:\r\n",
      "    print('[INFO] running process')\r\n",
      "    print(p.map(pull_timeseries, chunk_list))\r\n",
      "#print(\"[INFO] process complete.\")\r\n",
      "\r\n",
      "#pull_timeseries(task_rois, roi_df)\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat /projects/niblab/experiments/chocolate_milkshake/data/code/timeseries_pull.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit job file:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sbatch /projects/niblab/experiments/chocolate_milkshake/data/code/timeseries_pull.job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n"
     ]
    }
   ],
   "source": [
    "!squeue -u nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get timeseries roi task files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-049_task-milkshakeC_bb300_MNI152Asymm3mm_001.txt',\n",
       " 'sub-001_task-milkshakeB_bb300_MNI152Asymm3mm_001.txt',\n",
       " 'sub-112_task-milkshakeD_bb300_MNI152Asymm3mm_001.txt',\n",
       " 'sub-097_task-milkshakeC_bb300_MNI152Asymm3mm_001.txt',\n",
       " 'sub-020_task-milkshakeC_bb300_MNI152Asymm3mm_001.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view timeseries \n",
    "listdir('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300')[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view number of subject timeseries rois created/pulled\n",
    "len(glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300/*.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Timeseries into Matrix  <a class=\"anchor\" id=\"sixth-bullet\"></a>\n",
    "Combine timeseries roi files into, **one file per condition per participant**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-150', 'sub-151', 'sub-154']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_ids=list(data_dict.keys())\n",
    "subject_ids[-3:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through subject ids and combine in matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subject_matrices(subjects):\n",
    "    for subject_id in subjects:\n",
    "        tasks=list(data_dict[subject_id].keys())\n",
    "        for task in tasks:\n",
    "\n",
    "            # get roi texts for subject / condition\n",
    "            roi_txts = glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300/%s_%s*txt'%(subject_id,task))\n",
    "            df_lst=[]\n",
    "            for txt in roi_txts: \n",
    "                #print(txt)\n",
    "                df_temp = pd.read_csv(txt, sep=\"\\n\", header=None)\n",
    "                #print(df_temp)\n",
    "                df_lst.append(df_temp)\n",
    "            try:\n",
    "                df_concat= pd.concat(df_lst, axis=1, sort=False)\n",
    "                #print(df_concat)\n",
    "\n",
    "                # write output file \n",
    "                outfile='/projects/niblab/experiments/chocolate_milkshake/data/betaseries/subject_matrices/%s_%s-receipt.txt'%(subject_id,task)\n",
    "                #print('[INFO] making file %s'%outfile)\n",
    "                #df_concat.to_csv(outfile, header=None, index=None, sep='\\t')\n",
    "            except:\n",
    "                print('[INFO]error with %s condition %s, passing...'%(subject_id,task))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing 12 lists\n"
     ]
    }
   ],
   "source": [
    "roi_txts = glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/rois/big300/%s_%s*txt'%(subject_id,task))\n",
    "outfile='/projects/niblab/experiments/chocolate_milkshake/data/betaseries/subject_matrices/%s_%s.txt'%(subject_id,task)\n",
    "\n",
    "subject_chunks=chunks(subject_ids, 10)\n",
    "#subject_chunks[:2]\n",
    "\n",
    "print(\"[INFO] processing %s lists\"%len(subject_chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run parallel process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] making subject condition matrix from rois timeseries...\n",
      "[INFO]error with sub-088 condition task-milkshakeD, passing...\n",
      "[INFO]error with sub-032 condition task-milkshakeD, passing...\n",
      "[INFO]error with sub-033 condition task-milkshakeC, passing...\n",
      "[INFO]error with sub-015 condition task-milkshakeC, passing...\n",
      "[INFO]error with sub-081 condition task-milkshakeC, passing...\n",
      "[INFO] completed process.\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] making subject condition matrix from rois timeseries...\")\n",
    "\n",
    "with Pool(10) as p:\n",
    "    p.map(create_subject_matrices, subject_chunks)\n",
    "    \n",
    "print(\"[INFO] completed process.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick view of new files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-142_task-milkshakeB-receipt.txt',\n",
       " 'sub-143_task-milkshakeC-receipt.txt',\n",
       " 'sub-143_task-milkshakeA-receipt.txt',\n",
       " 'sub-144_task-milkshakeD-receipt.txt',\n",
       " 'sub-144_task-milkshakeA-receipt.txt']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/subject_matrices')[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob('/projects/niblab/experiments/chocolate_milkshake/data/betaseries/subject_matrices/*.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
